[
{
	"uri": "https://scientific-programming.github.io/",
	"title": "Homepage",
	"tags": [],
	"description": "",
	"content": " Scientific Programming This website aims to be a self contained basics course designed for scientists who need to do some programming as part of their research. The topics covered are:\n Containerisation - How can a team of developers, often working remotely from one another set up a consistent environment for developing their software? If you have ever been sent code by someone and not been able to run it, this section is for you\u0026hellip; We will show you how to configure a container to run a C/C++ or Python application using Docker.\n Version Control - No longer will you have 5 versions of your code in a folder with names like \u0026lsquo;main-working-18-04-2017.cpp\u0026rsquo;, \u0026lsquo;main-not-working-16-08-2018.cpp\u0026rsquo;\u0026hellip; We\u0026rsquo;ll teach how to set up a history of code development using the tool Git.\n Continuous integration and Testing - If you make a change to your code, how do you know that it\u0026rsquo;s not broken? If you\u0026rsquo;ve ever come to use a part of your code and realised that it no longer works because you changed something else, this will be useful to you. We will teach you how to write appropriate tests for scientific codes, and show you how to set up a continuous integration system for Git repositories.\n Documentation - What makes good documentation? At a minimum, what should the requirements be? In this, we\u0026rsquo;ll go through some examples and talk about and show some of the tools for documenting software.\n  "
},
{
	"uri": "https://scientific-programming.github.io/introduction/",
	"title": "Software Engineering in Science",
	"tags": [],
	"description": "",
	"content": " Why is it needed? The expectation is that your scientific code must be error free, within reason. However, there are many places where errors can creep in, and in general, scientists do not perform basic software engineering techniques which are designed to minimise \u0026ldquo;stupid\u0026rdquo; mistakes. Sources of errors can either be conceptual - a mistake in understanding of the theory - or in the implementation of the software used to solve problems. Here, we\u0026rsquo;re going to focus on the mistakes that come in from implementation issues, which really, are the easier ones to deal with. Let\u0026rsquo;s try and think about the issues that might happen when when things go wrong with software, both scientific and general.\nThere are a number of high profile examples which can illustrate for us the issues that might occur from coding errors.\nGeoffrey Chang Geoffrey Chang and coauthors published a series of papers in high profile journals which attempted to determine the structure of molecules through analysing X-Ray crystallography data. The research groups papers were very highly cited and influential. However, in 2006 Kasper Locher performed a similar technique to Chang to determine the structure for what should have been a similar crystal to one studied by Chang\u0026rsquo;s group. Instead, he found a 180\u0026deg; flip in the orientation of one helix, which suggested that the results were incorrect. Chang went back and looked at his software, and realised that two columns of data had been accidentally transposed, which resulted in the signs of charges in the molecular structure being flipped. In total, this led to retraction of 6 papers, and around five years of work.\nYou can read more about the impact of this here.\nReinhart and Rogoff Two economists, Reinhart and Rogoff published an influential paper \\\u0026ldquo;Growth in a time of Debt\\\u0026rdquo; on the topic of government debt to gross domestic product ratios. The results from their study showed that growth declined once the ratio reached around 60%, the growth in countries historically had begun to decline. The paper was notable for it\u0026rsquo;s use in political circles; it was cited by government figues in the UK, EU and US as the basis for reducing government spending.\nA PhD student in the US, Herndon, struggled to reproduce the results of the study, and eventually contacted the original authors of the paper requesting the non-public data that the study was based on. The authors passed this on, but Herndon and found a number of spreadsheet errors which meant that certain countries were not included in the historical data. On inclusion of these countries, the results from the paper still showed a decline in growth, but one which was substantially lower than as originally presented.\nAriane 5 Rocket Launch 1996 The launch of the first Ariane 5 rocket was a 10 year development and a $7 Billion cost for the European Space Agency. On the first test launch in June 1996 the trajectory of the rocket went of course 37 seconds in and the self destruct mechanism kicked in.\n  Investigations found that the inertial reference system had software bug, which was caused by the conversion of a 64-bit float containing the velocity into a 16-bit integer, and this caused an integer overflow. It turned out that this calculation was not even necessary on the Ariane 5, and had been inherited from software on the Ariane 4, but because this rocket reached much higher speeds, the rocket attempted to make correction for altitude deviation which hadn\u0026rsquo;t happened.\nThis was a particularly expensive mistake!\nSupercooled Water Very recent case - but went on for years. Researchers had conflicting results in simulations of supercooled water. Eventually, one group published all of their research software, which put pressure on the other group to do so. When they eventually did, it was found that they were using a very unconventional method of initialising their molecular dynamics simulations, which led to the spurious results.\nNHS Connecting for Health Stepping away from scientific software bugs, let\u0026rsquo;s look at how poor software design and oversight may hamper a different type of large software project, even when professional software developers are the ones writing it. It may surprise you to find out that in the UK, there is no national database of patient records. If you go to A\u0026amp;E on a Saturday night unconscious, in general, doctors will not be able to see your medical records until the Monday morning when your GP opens again.\nIn 2002, Tony Blair\u0026rsquo;s Labour government decided to rectify this, and in 2003 and 2004 awarded contracts to Accenture, Fujitsu, BT Health and Computer Sciences Corporation between 2002 and 2004, which the intention of building a complex set of regional systems which could integrate with one another. The initial projected timescale for this project was three years. The proposed system had an expected cost 2.3 Billion and would have been the biggest government IT project in the world.\nThe scheme was eventually cancelled in 2011 but 16 years later costs from fallout of this project are still escalating - currently at over £20 billion. Compare this, for example, to the UK science budget which in 2018 is £5 billion. A government report \u0026ldquo;Government and IT - a recipe for rip offs\u0026rdquo; in 2011 blamed lack of in-house technical knowledge and a tendency to build large complex projects that cannot adapt to changing requirements.\nMore examples  A trading glitch cost Knight Capital $440 Million dollars in 30 minutes. The Therac-25 Radiation Therapy machine bug killed 4 patients and injured two others because of integer overflow in software written by a single programmer. In 1998 the Mars Climate Orbiter crashed because of imperial vs metric units in interface between software. Y2K was caused by 32-bit integer commonly used to store dates overflowing. (Upcoming again in 2038\u0026hellip;) A 1999 Study on suicides after natural disasters counted deaths in one year twice and had to be retracted. *  What are the implications of badly written software?  It\u0026rsquo;s clear that complex systems are very hard to get right. This means that starting out when writing a programme is usually not the best way of approaching it - take some time to plan. Getting things wrong for you means bad science and a damaged career. If you have to retract some work because of what amounts to carelessness, you\u0026rsquo;re going to be known in your field for getting it wrong, and it will take a lot of work to recover your reputation. Retractions are also becoming more visible! If you work on large projects it can mean huge costs in time and money if you have to redo analysis. Poorly designed software is just as bad as bugs in well designed software!  What should we draw from this?  Clear that even professional software developers can get it wrong. Scientists in particular are not generally good programmers and are mostly self taught. Scientists do not have the resources to use all of the techniques from industry to avoid problems.  Reproducibility and Repeatability  Reproducibility - Gaining results which are close in agreement using the same methodology described Key concept of the scientific method Often scientific papers cannot be reproduced solely from the paper alone. How many of you have ever struggled to reproduce a result from a computational paper? Often this comes from inherent assumptions in modelling which are not discussed in the research literature itself. Very challenging to write a paper which is complete. Large and well discussed \\\u0026ldquo;reproducibility crisis\\\u0026rdquo;  A Changing Landscape? Think now about the requirements you\u0026rsquo;re being asked to meet for research in the UK. As EPSRC funded researchers, you are already required to: * Deposit the accepted manuscript in an institutional repository so that they are openly accessible within 3 months of acceptance. * All of your research data must now be made public and be available for up to 10 years after the last 3rd party access.\nYou need to care about these things if you want to stay in academia, because if you don\u0026rsquo;t meet the requirements, your publications are not countable towards REF, which directly impacts your career path. The motivations behind these policies is that as publicly funded researchers, the general public should be able to access information you produce (with some exceptions on national security or data privacy grounds).\nMoving on from funder requirements, we need to look at what publishers are starting to demand. It is becoming increasingly necessary for you to release the source code that generates your publications. See, for example, Nature Publishing Group\u0026rsquo;s publication guidelines, which are moving in this direction. Where high quality journals start, others will follow! Looking at one particularly odd example, a 2004 paper was retracted from BMC Evolutionary Biology after the author refused to let scientists from countries admitting refugees use of the software, as this breached the journal\u0026rsquo;s guidelines on software availability.\nThe other thing to note is that other scientists - and not just funders and publishers - are becoming more demanding regarding access to software, which the recognition that complex software is often not described adequately in research papers, making the results irreproducible. Government funded organisations such as the Software Sustainability Institute are actively pushing for more research code to be made open and maintainable, and provide training. There is now a whole new career path for \u0026lsquo;Research Software Engineers\u0026rsquo; - usually former academics with strong software skills, who can provide training to academics and who are included on grant applications to work on making the research software used maintainable.\nWhat will this course teach you? Everything in the following courses is designed to make it easier for you to writing good software. In the software industry these just some starting points from which all else follows. If you are not doing any one of these things (with the exception of containerisation), you are almost certainly not writing good software. The main point is that scientific software is not some special case - it is just as complex as software in industry, where all of these are standard practice.\n"
},
{
	"uri": "https://scientific-programming.github.io/containers/",
	"title": "Containers",
	"tags": [],
	"description": "",
	"content": " What are containers? Containers provide a mechanism for setting up an environment with many software dependencies. They can be simple, with a limited number of simple programmes installed, or can be used to set up complex software. In addition, they allow software from different operating systems to be used natively; an Ubuntu package could be used on a RHEL Linux system without any issues.\nUsers write scripts in a simple standardised way, and this is primarily bundled with the project, and passed on to other developers in order to give them the same environment to work from when developing software. A built container can also be hosted online freely, which is useful when building the dependencies takes a long time.\nThese features might seem familiar if you\u0026rsquo;ve come across Virtual Machines in the past. The primary advantage of containers is that they do not incur the performance penalty that virtual machines do, if they are run on a Linux operating system (in general).\nWhat are containers not? Containers are not always a great way to distribute scientific software to people who are going to use it, particularly when the code is compiled. This is because hardware variances mean that software has generally got to be compiled for the oldest possible machine it could be used for. This means that for optimal performance, multiple versions of the same container need to be compiled. This is particularly important when running high performance software which runs on supercomputers.\nBecause of this, making your code run in a container is not \u0026lsquo;enough\u0026rsquo; to distribute software; it is still necessary to make a comprehensive list of the dependencies necessary to run the software, with versions. However, it takes the pain out of having multiple developers working in different environments which what may prove to be incompatible versions of dependencies. It also should not be used as a way of avoiding updating scientific software because it now runs everywhere.\nTerminology  Host - A physical computer running VM/container. Container - An operating system level virtualised environment in which software is installed. Image - A container which has been saved to a file. Hypervisor - The software which runs a virtual machine. Kernel - Core OS components and functions.    Comparisons with Virtual Machines As mentioned before, despite not being virtual machines, containers act like them in many ways.\nHow are containers like VMs?  Isolated environment - Processes run isolated from other processes - they can’t access hardware resources they aren’t allocated. They are independent - Generally you can be given a container image or a virtual machine image and use that to run a piece of software without doing anything else.  How are containers not like VMs?  They use Kernel features of the host - Linux supports process and resource partitioning and isolation (cgroups, OverlayFS, kernel namespacing), which allows containers to use a subset of resources.\n VMs require a Hypervisor - The hypervisor is a software based emulation layer for computer hardware and so it is generally 20% slower running software in a VM than natively, even with Intel Vf-X, Sun GridEngine. Free hypervisors slow; commercial are expensive!\n Generally containers are command-line only - With VMs it is very easy to get a full desktop environment. With containers this use case is generally not well supported.\n They take up much less space - Virtual Machines have to bundle the whole operating system, including components which would be the same on the host system. Containers, by virtue of using the host system\u0026rsquo;s kernel (at least on Linux), can therefore take up much less room.\n  Potential Use Cases for Containers as a Scientist Consider the following, which are all valid use cases:\n A new PhD student joins your lab. He isn\u0026rsquo;t an experienced programmer, and setting him up with all of the dependencies will take some time. Using a container means he can get all of the dependencies and a copy of the software working on his computer in minutes.\n An old piece of software runs fine on Ubuntu, but a colleague hasn\u0026rsquo;t been able to install a necessary package because it\u0026rsquo;s not available on Windows which is what he uses.\n You\u0026rsquo;ve just been given an Microsoft Azure Academic Grant, and you now want to run thousands of copies of your research software in the cloud, and you want to avoid a complicated install process.\n You have a data analysis script that chugs away on your desktop for every set of simulation data you produce. However, you run thousands of simulations per week, and the data analysis script takes some time to run. You might install this script into a container, and use that as the basis for running the data analysis on a large cluster.\n  "
},
{
	"uri": "https://scientific-programming.github.io/containers/tutorial1/",
	"title": "Setting up the Software",
	"tags": [],
	"description": "",
	"content": "    For all of the following tutorials, we will use Docker as the container software of choice. How to install Docker varies quite a lot between different operating systems.\nPlease follow the instructions relevant to you:\nLinux "
},
{
	"uri": "https://scientific-programming.github.io/containers/tutorial2/",
	"title": "Getting Started with Docker",
	"tags": [],
	"description": "",
	"content": " First Steps 1) Make an account on the website https://hub.docker.com\nMake the username something sensible as we\u0026rsquo;ll have to use it soon!\n1) If you haven\u0026rsquo;t already, try \u0026ldquo;docker run ubuntu:18.04\u0026rdquo;. This downloads an image containing Ubuntu 18.04.\n2) Now, we\u0026rsquo;ll create a file called \u0026ldquo;Dockerfile\u0026rdquo; in a single folder. The Dockerfile is a configuration script for building an image.\n Create a directory by doing:  mkdir docker-tutorial  Change directory into the folder:  cd docker-tutorial 3) Create a file called Dockerfile in this directory, and put as the first line:\nfromubuntu:18.04\u0026#39; 4) Now, we can start installing things inside the image. We do this by adding lines to the Dockerfile; a command to run is prefaced by \u0026ldquo;RUN\u0026rdquo;. If you\u0026rsquo;re not familiar with Linux, and are primarily a Windows or Mac user, it may seem a little odd to install programmes using typed out commands, but it can be very powerful. For Ubuntu, there are basically two commands you need to know.\nFirst, we\u0026rsquo;ll update the list of Ubuntu packages which can be installed; note that this is almost always necessary. To do this, add:\nRUN apt-get update to the file.\n6) Once this is completed, you can then choose to install programmes. We\u0026rsquo;re going to use Python for this example, but you can pick any programmes you like for your own Docker containers. Here, we just add the line:\nRUN apt-get install -y python3 which tells Ubuntu to install Python 3 in the container. The \u0026ldquo;-y\u0026rdquo; flag here just tells apt-get, the programme used in Ubuntu for installing programmes, not to prompt for confirmation.\nNow, you have a script which tells Docker to build a container which: * Is based on Ubuntu 18.04. You could change this to another Linux distribution if you wanted, such as CentOS. * Contains Python 3.\nThis is the general principle of containers - you build them up in steps until they have everything you need to run real applications.\nNow, we can tell Docker to run a command when the container is launched. We do this using a slightly different syntax:\nCMD /bin/bash  This just tells Docker to launch the Bash shell. From this, we can launch all of the programmes installed into the container. Alternatively, we could just as easily write:\nCMD / 7) Now let's actually build the container image from the script file. We do this using the following command - replace \u0026quot;YOURUSERNAME\u0026quot; with your username for the account we created with Dockerhub earlier. ```Bash docker build . -t YOURUSERNAME/myimage  Breaking this command down:\n Docker is the application.\n We\u0026rsquo;re running Docker\u0026rsquo;s build command\n \u0026rdquo;.\u0026rdquo; refers to the file location - it\u0026rsquo;s saying \u0026ldquo;build the Dockerfile in this folder\u0026rdquo;\n -t YOURUSERNAME/myimage - if you\u0026rsquo;re not familiar with Linux, adding a dash is a common way of signalling how to pass information to a command. Here, \u0026ldquo;-t\u0026rdquo; just means build the image with the tag YOURUSERNAME/myimage\n  More concepts Every time you add another command to the script, you create a new layer. A layer is the essentially just a list of differences between the previous command and the present one. Your container image is built up of multiple layers. If you want to add a new command, you don\u0026rsquo;t have to rebuild completely from scratch - Docker is clever enough to start from the last common layer. These layers do take up storage space, however.\nThat means though, if you change the programmes installed with apt-get on the second line of the script, all subsequent steps must be repeated, because Docker can\u0026rsquo;t work out if subsequent steps are independent or not of each other.\n7) Now we\u0026rsquo;ve installed python3 in the image, how do we use it?\nWe can do this in two ways - similar but quite different!\n1) Start a container from the image interactively, and launch the programme:\nTo run interactively, we must add the \u0026ldquo;-i\u0026rdquo; flag. If we don\u0026rsquo;t do this, the programme will launch, but will freeze!\ndocker run -i -t YOURUSERNAME/myimage Then, just run\npython3  to launch the Python interpreter.\n2) * Create a container from the image, and give it the name \u0026lsquo;mytest\u0026rsquo;\ndocker create --name mytest YOURUSERNAME/myimage  Then, start the container:  docker start --name mytest *\nSaving the Container 1) We can save the docker container to a file with\ndocker save YOURUSERNAME/mycontainer \u0026gt; myimage.tar You can compress the image if you want with the command\ngzip -f myimage.tar You can load it again with\ndocker load myimage.tar.gz 2) However, it\u0026rsquo;s not normally necessary to save containers like this - much easier just to use Docker Hub. Free uploads of containers if public, one private container per account.\nMake a repository called \u0026lsquo;mycontainer\u0026rsquo; on your Dockerhub account\n3) Now, on your computer, run the command:\ndocker login  You will be prompted for your username and password for Dockerhub. Enter them.\n11) Now, we can publish the container online using:\ndocker push YOURUSERNAME/mycontainer 12) Your container should now be available online. That means, someone else can download it using the \u0026lsquo;docker pull\u0026rsquo; command, and run the same programmes as you in the same way.\n13) Just to prove it to you, let\u0026rsquo;s now delete the containers.\nThere are lots of commands for deleting containers and images - this is quite confusing!\nIf you want to remove everything, you can run:\ndocker system prune Deletes everything that are not associated with a running container - \u0026ldquo;dangling\u0026rdquo;. Add the \u0026ldquo;-a\u0026rdquo; flag to remove additionally any stopped containers and all unused images.\nIf you just want to remove a specific image, you can run\ndocker images This gives a list of all images you\u0026rsquo;ve created, including intermediate layers. Copy the image id (the long string of numbers) of the image you want to remove:\ndocker rmi IMAGEID You may need to add the flag \u0026lsquo;-f\u0026rsquo; if you get an error here:\ndocker rmi IMAGEID -f  Note: if other images depend on the image you are deleting, they will also be deleted!\nRemove all images:\ndocker images -a docker rmi $(docker images -a -q) 14) Now pull the image we uploaded:\ndocker pull YOURUSERNAME/dependencies  Further steps TBD: Check Windows mount path syntax\nOften, we want to install programmes in the container in order to manage dependencies, but we need to have them act on files stored on the computer itself. This can easily be achieved by mounting folders into the container, so that they are visible inside it.\nTBD: Mounting Ports: Explain what ports are? Networking end points - send messags between? Is this sufficient? TCP vs UDB - Docker uses TCP by default. Not sure this is relevant to mention.\n"
},
{
	"uri": "https://scientific-programming.github.io/version-control/",
	"title": "Version Control",
	"tags": [],
	"description": "",
	"content": " What is Version Control? Simply put, it\u0026rsquo;s a way of keeping old versions of your software or documents. If you\u0026rsquo;ve ever worked in a business environment, you might be familiar with Microsoft SharePoint, and the concepts of checking in and out documents. This is an example of version control. Here, however, we\u0026rsquo;re going to teach you how to use Git, which is a more general purpose version control software. There are alternatives (Mercurial and SVN), but Git seems to have become particularly popular with the launch of the site GitHub.\nWhy is it useful? The concept of version control is something which people do without thinking about. It\u0026rsquo;s common to keep older versions of documents in general, and the same applies to code. However, using software to do this for code is not very common in academia, and most people end up with situations something like that in the above comic.\nThink about how you might behave when you find a bug in your code somewhere. You might know that it didn\u0026rsquo;t previously exist and so an older version of a function was fine. With your code tracked in version control, you can look back at old versions of your code, with notes about what changes were made between versions.\nHow is it useful for scientists in particular? There are a number of really strong arguments for using version control as a scientist. When you run a simulation for example, it is good practice to be able to record the exact version of the code used to generate your results. If you don\u0026rsquo;t do so, and you find at a later date that you can\u0026rsquo;t reproduce your simulation results, you can then go back to the old version and find out why this might be the case.\nVersion control is useful especially for writing papers when you have multiple collaborators. When this is the case, you can have a master copy of a document written in LaTeX, which every person can work on together. Certain commands let you see which author wrote or edited each line, and so you know exactly who is responsible for particular changes, making it easy to ask for clarification or make suggestions to the right person as necessary.\n"
},
{
	"uri": "https://scientific-programming.github.io/version-control/tutorial1/",
	"title": "Getting Started",
	"tags": [],
	"description": "",
	"content": " Getting Started with Version Control 1) Open your terminal, or Git Bash.\n2) Set your name and username with Git. This labels modifications to files you do and associates them with you!\ngit config --global user.name \u0026#34;Ryan Pepper\u0026#34; git config --global user.email \u0026#34;ryan.pepper@soton.ac.uk\u0026#34; 3) Set your favourite text editor by running the appropriate command below:\n# Atom git config --global core.editor \u0026#34;atom --wait\u0026#34; # nano git config --global core.editor \u0026#34;nano -w\u0026#34; # Sublime Text (Mac) git config --global core.editor \u0026#34;/Applications/Sublime\\ Text.app/Contents/SharedSupport/bin/subl -n -w\u0026#34; # Sublime Text (Win, 64-bit install) git config --global core.editor \u0026#34;\u0026#39;c:/program files/sublime text 3/sublime_text.exe\u0026#39; -w\u0026#34; # Notepad++ (Win, 64-bit install) git config --global core.editor \u0026#34;\u0026#39;c:/program files/Notepad++/notepad++.exe\u0026#39; -multiInst -notabbar -nosession -noPlugin\u0026#34; # Emacs git config --global core.editor \u0026#34;emacs\u0026#34; # Vim git config --global core.editor \u0026#34;vim\u0026#34; 4) We\u0026rsquo;re going to create a folder with the command \u0026ldquo;mkdir\u0026rdquo;, and change into that directory with \u0026ldquo;cd\u0026rdquo;.\ncd ~ mkdir project cd project 5) Now, we make the folder into a git repository. This means that git will start to keep track of files created in the folder.\ngit init 6) The command \u0026ldquo;ls\u0026rdquo; shows the directories contents. If we use the command \u0026ldquo;ls -a\u0026rdquo; - the \u0026ldquo;-a\u0026rdquo; flag means that we see hidden files, shows us that a new folder called \u0026ldquo;.git\u0026rdquo; has been created.\n7) We can run\ngit status to show that everything has worked correctly. You should see something like the following:\n# On branch master  #  # Initial commit  # nothing to commit  (create/copy files and use \u0026#34;git add\u0026#34; to track) Git status is a really useful command which gives you information about the \u0026lsquo;state\u0026rsquo; you are currently in.\n8) Let\u0026rsquo;s create a file; open the text editor you chose earlier, and save a file called \u0026ldquo;workshop.txt\u0026rdquo; in the directory you\u0026rsquo;re in.\nWrite something in the file, such as:\nI\u0026#39;m learning how to use Version Control with Git! and save it.\n9) Now, let\u0026rsquo;s try running \u0026lsquo;git status\u0026rsquo; again. What you should see is that now, changes you\u0026rsquo;ve made show up. As of yet, the changes you have made are not saved.\nOn branch master No commits yet Untracked files: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed) workshop.txt nothing added to commit but untracked files present (use \u0026#34;git add\u0026#34; to track) An untracked file is just a file that we haven\u0026rsquo;t told Git to watch in any way - it is completely ignored. To track the file we created, we use the command:\ngit add workshop.txt Running the command \u0026ldquo;git status\u0026rdquo; again:\nOn branch master No commits yet Changes to be committed: (use \u0026#34;git rm --cached \u0026lt;file\u0026gt;...\u0026#34; to unstage) new file: workshop.txt 10) Now, we\u0026rsquo;re going to \u0026lsquo;commit\u0026rsquo; our changes - basically, take a snapshot of them at this particular time.\nYou have two options\ni) Run the command\ngit commit This will bring up the text editor you chose earlier. Type a message about the changes you have made so that the file looks something like this:\nAdded text to workshop.txt Now save the file.\nii) Alternatively, skip opening the text editor with:\ngit commit -m \u0026ldquo;Added text to workshop.txt\u0026rdquo;\nPersonally, this is my preferred way of doing it as it\u0026rsquo;s a bit quicker.\n11) Now make some more changes - add another line of text to the file workshop.txt, and commit them again.\n12) Now we\u0026rsquo;re going to look at the record we\u0026rsquo;ve made so far. Try running the command:\ngit log What you should see is something like the following:\ncommit 3ef8ea1e42fc071b8f8121ba80419b9df6f5d983 (HEAD -\u0026gt; master) Author: Ryan Pepper \u0026lt;ryan.pepper@soton.ac.uk\u0026gt; Date: Wed Oct 24 15:04:12 2018 +0100 Added more text to workshop.txt commit dc6b701bcdbff38fa8a9800f8173f88d514090ac Author: Ryan Pepper \u0026lt;ryan.pepper@soton.ac.uk\u0026gt; Date: Wed Oct 24 14:17:36 2018 +0100 Add text to workshop.txt Breaking this down - there are two sections, for the two commits you\u0026rsquo;ve made so far, ordered from newest to oldest.\nThe big long strings are a label for a particular set of changes. Author and date are self-explanatory, and the text below that is the message\n13) Now, let\u0026rsquo;s say that you need to go back in time and look at how the file looked some time ago. We could just delete the text, but in more complicated cases, that\u0026rsquo;s not sufficient. There is an easy way to go back.\nCopy about 10 or so of the first letters and numbers of the commit that you want to see. Then run the command:\ngit checkout dc6b701bcdbff You will see some output:\nNote: checking out \u0026#39;dc6b701bcdbff38f\u0026#39;. You are in \u0026#39;detached HEAD\u0026#39; state. You can look around, make experimental changes and commit them, and you can discard any changes you make in this state without impacting anything. You\u0026rsquo;re now in a working environment with the old set of changes - if you open the file again, you can see the latest committed changes have disappeared. Don\u0026rsquo;t worry! They\u0026rsquo;re safe. You\u0026rsquo;re in something called a \u0026lsquo;detached HEAD\u0026rsquo; state. This is often a source of a lot of confusion for people new to Git, because if you make commits in this state, they will get lost. In order to learn what this means, we\u0026rsquo;ll need to understand about branches.\nBranches Now is a good time to introduce the concept of a branch. Branches are basically a parallel stream of commits that you can work on separately, and switch to at any time. The branch you are on by default is known as the \u0026ldquo;master\u0026rdquo; branch. You can have as many branches as you like in a repository, and they can act as a really useful place to work on adding a new feature to the code, or fixing a bug. They act like a parallel stream of commits, and can split off from the master branch at any point.\n   Each circle here represents a commit. At a particular commit, you can split off and create a new branch of work while other people work on the master branch. Then, later, you can merge your work back into the master branch.   As mentioned before, when you are in detached HEAD state, anything you do is discarded. However, you can keep changes you make here if you create a new branch like so:\ngit checkout -b mynewbranch HEAD is now at dc6b701 Add text to workshop.txt This is a two stage process. Git checkout is for switching between branches; the \u0026ldquo;-b\u0026rdquo; flag creates new ones.\nIf at any point you need to see a list of all of your branches, you can just run:\ngit branch  And you should see some output like:\n master * mynewbranch  The star here just indicates which branch you are currently working on.\n15) From here, we can make changes. Add some more text in the file workshop.txt and commit the changes.\nYou can switch back to the original history by running the command:\ngit checkout master 16) Now you can try and merge the changes you made in the \u0026lsquo;mynewbranch\u0026rsquo; branch back into the \u0026lsquo;master\u0026rsquo; branch. To do this, make sure you\u0026rsquo;re in the master branch and then run the command:\ngit merge mybranch However, you may see an error message:\nAuto-merging workshop.txt CONFLICT (content): Merge conflict in workshop.txt Automatic merge failed; fix conflicts and then commit the result.  What this means is that Git cannot automatically reconcile the differences between the version of the file in your new branch, and the version of the file in your master branch. This is called a \u0026lsquo;merge conflict\u0026rsquo; That means you manually need to edit the file. Edit the file and you will see three odd lines with special markers:\nHello, we've got a file in here! \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; HEAD Added a line of text on the branch! ======= Added another line to the file. \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; mybranch  The \u0026ldquo;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; HEAD\u0026rdquo; means that what follows is text on the head of the current branch - i.e. mynewbranch.\nThe \u0026ldquo;=======\u0026rdquo; acts as a seperator\nThe \u0026ldquo;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; master\u0026rdquo; signals the end of the conflicting changes on the master branch.\nTo reconcile, simply delete these three lines, to make a definitive version of the file, and save it. Do a \u0026lsquo;git add\u0026rsquo; and then \u0026lsquo;git commit\u0026rsquo;. It\u0026rsquo;s worth mentioning that when working on code projects, the longer you work on a branch for, the more likely it is to diverge from the master branch, which can make reconciling your changes harder.\n"
},
{
	"uri": "https://scientific-programming.github.io/version-control/tutorial2/",
	"title": "GitHub and Collaborating",
	"tags": [],
	"description": "",
	"content": " Storing your repository somewhere safe You have a history of your changes locally, but that\u0026rsquo;s not much good if your hard drive fails. We\u0026rsquo;ll now show you how keep a history remotely.\nGit is known as a \u0026lsquo;distributed version control\u0026rsquo; system. Generally, you host a repository somewhere online. There are lots of different providers for this.\n GitHub - free! Lots of integrations with other services. Limited number or private repositories, but you can send off proof of academic status to get an unlimited number.\n GitLab - also free. Unlimited number of private repositories. Also allows local hosting - for e.g. in the University of Southampton, there is a private GitLab instance hosted internally, which can be used for sensitive projects.\n BitBucket - Has a lot of commercial products that are used in industry - good issue trackers.\n  For this exercise, we\u0026rsquo;ll use GitHub, but in practice there is not much between them.\n1) Create an account on github.com\n2) Once done, click the \u0026ldquo;+\u0026rdquo; arrow in the top right hand corner, and click \u0026ldquo;New repository\u0026rdquo;\n3) Type in a name and description for your repository:\nYou\u0026rsquo;ll now get a list of commands to type; the ones you want are:\ngit remote add origin https://github.com/rpep/mytestrepo.git git push -u origin master You\u0026rsquo;ll get asked for your username and password for GitHub - enter these.\nNow refresh the page, and you\u0026rsquo;ll see the file you had has appeared online!\n4) Now - in pairs - one of you go to the Git repository of your neighbour. This will be\nhttps://github.com/their-username/their-repository-name\nClick \u0026lsquo;Fork\u0026rsquo;. This will make a copy of their repository on your GitHub.\n5) Now, copy their repository to your computer with the command:\ngit clone https://github.com/yourusername/their-repository-name.git 6) Move into the folder:\ncd their-repository-name And make your own change to the file.\n7) Commit it as before:\ngit commit -m \u0026#34;Making a change to my partner\u0026#39;s repository\u0026#34; 8) Now push the change online:\ngit push 9) Go back to GitHub.\nClick \u0026ldquo;New Pull Request, and then \u0026ldquo;Create New Pull Request\u0026rdquo; on the next page.\nAdd in some information about the changes you made, and then \u0026ldquo;Create pull request\u0026rdquo;\n10) Now, your partner needs to go back to their version of the repository, and look at the tab labelled \u0026ldquo;Pull Requests\u0026rdquo;\nScroll to the bottom, and then press \u0026ldquo;Merge pull request\u0026rdquo;\n12) Pull these changes to your repository using \u0026lsquo;git pull\u0026rsquo;.\n"
},
{
	"uri": "https://scientific-programming.github.io/version-control/tutorial3/",
	"title": "Discarding Temporary Changes",
	"tags": [],
	"description": "",
	"content": " Discarding channges 1) If you make some changes to the file workshop.txt, but then decide that they weren\u0026rsquo;t correct or were unnecessary, you can easily get back to the head of the branch with the following command:\ngit reset HEAD workshop.txt This permanently discards these changes.\n2) Alternatively, if you want to hide the changes now, but might come back to them, you can use:\ngit stash  This creates a list of changes which are stored, but not committed, and which you can recover later. You can stash multiple times. Change your file and then stash it, and then repeat that again a few times.\n3) To look at a list of the stashes you\u0026rsquo;ve made, just type:\ngit stash list  4) To recover the most recent set of changes, you can just type\ngit stash apply If you want a different set, you can type:\ngit stash apply stash@{2} If there is a clash between your current commit and the stashed code, you will get a merge conflict which you\u0026rsquo;ll need to resolve.\n5) If you recover something from a stash, but then decide you don\u0026rsquo;t want it anymore, you can achieve this by \u0026lsquo;unapplying\u0026rsquo; the stash, using the following command:\ngit stash show -p stash@{2}| git apply -R If you don\u0026rsquo;t specify which stash from the list you recovered from, git will just assume you chose the most recent one.\n"
},
{
	"uri": "https://scientific-programming.github.io/cheatsheet/",
	"title": "Command Cheatsheet",
	"tags": [],
	"description": "",
	"content": "The following is a list of standard commands in cmd on Windows or Bash on *nix systems. It\u0026rsquo;s by no means a comprehensive list - these are just to help you\nSometimes the commands I\u0026rsquo;ll show (which are used for navigating around on Linux or Unix based systems like Macs) don\u0026rsquo;t work in Windows. So here, I\u0026rsquo;ve put a list of things you might want to do, and the commands in both Windows and Linux.\n   Concept Windows cmd command Linux     Run a file filenme ./filename   Change directory into folder X cd X cd X   List files dir ls   Show the current directory cd pwd   Copy filenamed A to B copy A B cp A B   Delete file A del A rm A   Delete folder A rmdir A rm -r A   Move file A to B move A B mv A B   Create a folder called A mkdir A mkdir A    "
},
{
	"uri": "https://scientific-programming.github.io/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://scientific-programming.github.io/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]