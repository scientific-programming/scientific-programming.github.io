[
{
	"uri": "https://scientific-programming.github.io/",
	"title": "Homepage",
	"tags": [],
	"description": "",
	"content": " Scientific Programming This website aims to be a self contained basics course designed for scientists who need to do some programming as part of their research. The topics covered are:\n Containerisation - How can a team of developers, often working remotely from one another set up a consistent environment for developing their software? If you have ever been sent code by someone and not been able to run it, this section is for you\u0026hellip; We will show you how to configure a container to run a C/C++ or Python application using Docker.\n Version Control - No longer will you have 5 versions of your code in a folder with names like \u0026lsquo;main-working-18-04-2017.cpp\u0026rsquo;, \u0026lsquo;main-not-working-16-08-2018.cpp\u0026rsquo;\u0026hellip; We\u0026rsquo;ll teach how to set up a history of code development using the tool Git.\n Continuous integration and Testing - If you make a change to your code, how do you know that it\u0026rsquo;s not broken? If you\u0026rsquo;ve ever come to use a part of your code and realised that it no longer works because you changed something else, this will be useful to you. We will teach you how to write appropriate tests for scientific codes, and show you how to set up a continuous integration system for Git repositories.\n Documentation - What makes good documentation? At a minimum, what should the requirements be? In this, we\u0026rsquo;ll go through some examples and talk about and show some of the tools for documenting software.\n  "
},
{
	"uri": "https://scientific-programming.github.io/introduction/",
	"title": "Software Engineering in Science",
	"tags": [],
	"description": "",
	"content": " Why is it needed? The expectation is that your scientific code must be error free, within reason. However, there are many places where errors can creep in, and in general, scientists do not perform basic software engineering techniques which are designed to minimise \u0026ldquo;stupid\u0026rdquo; mistakes. Sources of errors can either be conceptual - a mistake in understanding of the theory - or in the implementation of the software used to solve problems. Here, we\u0026rsquo;re going to focus on the mistakes that come in from implementation issues, which really, are the easier ones to deal with. Let\u0026rsquo;s try and think about the issues that might happen when when things go wrong with software, both scientific and general.\nThere are a number of high profile examples which can illustrate for us the issues that might occur from coding errors.\nGeoffrey Chang Geoffrey Chang and coauthors published a series of papers in high profile journals which attempted to determine the structure of molecules through analysing X-Ray crystallography data. The research groups papers were very highly cited and influential. However, in 2006 Kasper Locher performed a similar technique to Chang to determine the structure for what should have been a similar crystal to one studied by Chang\u0026rsquo;s group. Instead, he found a 180\u0026deg; flip in the orientation of one helix, which suggested that the results were incorrect. Chang went back and looked at his software, and realised that two columns of data had been accidentally transposed, which resulted in the signs of charges in the molecular structure being flipped. In total, this led to retraction of 6 papers, and around five years of work.\nYou can read more about the impact of this here.\nReinhart and Rogoff Two economists, Reinhart and Rogoff published an influential paper \\\u0026ldquo;Growth in a time of Debt\\\u0026rdquo; on the topic of government debt to gross domestic product ratios. The results from their study showed that growth declined once the ratio reached around 60%, the growth in countries historically had begun to decline. The paper was notable for it\u0026rsquo;s use in political circles; it was cited by government figues in the UK, EU and US as the basis for reducing government spending.\nA PhD student in the US, Herndon, struggled to reproduce the results of the study, and eventually contacted the original authors of the paper requesting the non-public data that the study was based on. The authors passed this on, but Herndon and found a number of spreadsheet errors which meant that certain countries were not included in the historical data. On inclusion of these countries, the results from the paper still showed a decline in growth, but one which was substantially lower than as originally presented.\nAriane 5 Rocket Launch 1996 The launch of the first Ariane 5 rocket was a 10 year development and a $7 Billion cost for the European Space Agency. On the first test launch in June 1996 the trajectory of the rocket went of course 37 seconds in and the self destruct mechanism kicked in.\n  Investigations found that the inertial reference system had software bug, which was caused by the conversion of a 64-bit float containing the velocity into a 16-bit integer, and this caused an integer overflow. It turned out that this calculation was not even necessary on the Ariane 5, and had been inherited from software on the Ariane 4, but because this rocket reached much higher speeds, the rocket attempted to make correction for altitude deviation which hadn\u0026rsquo;t happened.\nThis was a particularly expensive mistake!\nSupercooled Water Very recent case - but went on for years. Researchers had conflicting results in simulations of supercooled water. Eventually, one group published all of their research software, which put pressure on the other group to do so. When they eventually did, it was found that they were using a very unconventional method of initialising their molecular dynamics simulations, which led to the spurious results.\nNHS Connecting for Health Stepping away from scientific software bugs, let\u0026rsquo;s look at how poor software design and oversight may hamper a different type of large software project, even when professional software developers are the ones writing it. It may surprise you to find out that in the UK, there is no national database of patient records. If you go to A\u0026amp;E on a Saturday night unconscious, in general, doctors will not be able to see your medical records until the Monday morning when your GP opens again.\nIn 2002, Tony Blair\u0026rsquo;s Labour government decided to rectify this, and in 2003 and 2004 awarded contracts to Accenture, Fujitsu, BT Health and Computer Sciences Corporation between 2002 and 2004, which the intention of building a complex set of regional systems which could integrate with one another. The initial projected timescale for this project was three years. The proposed system had an expected cost 2.3 Billion and would have been the biggest government IT project in the world.\nThe scheme was eventually cancelled in 2011 but 16 years later costs from fallout of this project are still escalating - currently at over £20 billion. Compare this, for example, to the UK science budget which in 2018 is £5 billion. A government report \u0026ldquo;Government and IT - a recipe for rip offs\u0026rdquo; in 2011 blamed lack of in-house technical knowledge and a tendency to build large complex projects that cannot adapt to changing requirements.\nMore examples  A trading glitch cost Knight Capital $440 Million dollars in 30 minutes. The Therac-25 Radiation Therapy machine bug killed 4 patients and injured two others because of integer overflow in software written by a single programmer. In 1998 the Mars Climate Orbiter crashed because of imperial vs metric units in interface between software. Y2K was caused by 32-bit integer commonly used to store dates overflowing. (Upcoming again in 2038\u0026hellip;) A 1999 Study on suicides after natural disasters counted deaths in one year twice and had to be retracted. *  What are the implications of badly written software?  It\u0026rsquo;s clear that complex systems are very hard to get right. This means that starting out when writing a programme is usually not the best way of approaching it - take some time to plan. Getting things wrong for you means bad science and a damaged career. If you have to retract some work because of what amounts to carelessness, you\u0026rsquo;re going to be known in your field for getting it wrong, and it will take a lot of work to recover your reputation. Retractions are also becoming more visible! If you work on large projects it can mean huge costs in time and money if you have to redo analysis. Poorly designed software is just as bad as bugs in well designed software!  What should we draw from this?  Clear that even professional software developers can get it wrong. Scientists in particular are not generally good programmers and are mostly self taught. Scientists do not have the resources to use all of the techniques from industry to avoid problems.  Reproducibility and Repeatability  Reproducibility - Gaining results which are close in agreement using the same methodology described Key concept of the scientific method Often scientific papers cannot be reproduced solely from the paper alone. How many of you have ever struggled to reproduce a result from a computational paper? Often this comes from inherent assumptions in modelling which are not discussed in the research literature itself. Very challenging to write a paper which is complete. Large and well discussed \\\u0026ldquo;reproducibility crisis\\\u0026rdquo;  A Changing Landscape? Think now about the requirements you\u0026rsquo;re being asked to meet for research in the UK. As EPSRC funded researchers, you are already required to: * Deposit the accepted manuscript in an institutional repository so that they are openly accessible within 3 months of acceptance. * All of your research data must now be made public and be available for up to 10 years after the last 3rd party access.\nYou need to care about these things if you want to stay in academia, because if you don\u0026rsquo;t meet the requirements, your publications are not countable towards REF, which directly impacts your career path. The motivations behind these policies is that as publicly funded researchers, the general public should be able to access information you produce (with some exceptions on national security or data privacy grounds).\nMoving on from funder requirements, we need to look at what publishers are starting to demand. It is becoming increasingly necessary for you to release the source code that generates your publications. See, for example, Nature Publishing Group\u0026rsquo;s publication guidelines, which are moving in this direction. Where high quality journals start, others will follow! Looking at one particularly odd example, a 2004 paper was retracted from BMC Evolutionary Biology after the author refused to let scientists from countries admitting refugees use of the software, as this breached the journal\u0026rsquo;s guidelines on software availability.\nThe other thing to note is that other scientists - and not just funders and publishers - are becoming more demanding regarding access to software, which the recognition that complex software is often not described adequately in research papers, making the results irreproducible. Government funded organisations such as the Software Sustainability Institute are actively pushing for more research code to be made open and maintainable, and provide training. There is now a whole new career path for \u0026lsquo;Research Software Engineers\u0026rsquo; - usually former academics with strong software skills, who can provide training to academics and who are included on grant applications to work on making the research software used maintainable.\nWhat will this course teach you? Everything in the following courses is designed to make it easier for you to writing good software. In the software industry these just some starting points from which all else follows. If you are not doing any one of these things (with the exception of containerisation), you are almost certainly not writing good software. The main point is that scientific software is not some special case - it is just as complex as software in industry, where all of these are standard practice.\n"
},
{
	"uri": "https://scientific-programming.github.io/containers/",
	"title": "Containers",
	"tags": [],
	"description": "",
	"content": " What are containers? Containers provide a mechanism for setting up an environment with many software dependencies. They can be simple, with a limited number of simple programmes installed, or can be used to set up complex software. In addition, they allow software from different operating systems to be used natively; an Ubuntu package could be used on a RHEL Linux system without any issues.\nUsers write scripts in a simple standardised way, and this is primarily bundled with the project, and passed on to other developers in order to give them the same environment to work from when developing software. A built container can also be hosted online freely, which is useful when building the dependencies takes a long time.\nThese features might seem familiar if you\u0026rsquo;ve come across Virtual Machines in the past. The primary advantage of containers is that they do not incur the performance penalty that virtual machines do, if they are run on a Linux operating system (in general).\nWhat are containers not? Containers are not always a great way to distribute scientific software to people who are going to use it, particularly when the code is compiled. This is because hardware variances mean that software has generally got to be compiled for the oldest possible machine it could be used for. This means that for optimal performance, multiple versions of the same container need to be compiled. This is particularly important when running high performance software which runs on supercomputers.\nBecause of this, making your code run in a container is not \u0026lsquo;enough\u0026rsquo; to distribute software; it is still necessary to make a comprehensive list of the dependencies necessary to run the software, with versions. However, it takes the pain out of having multiple developers working in different environments which what may prove to be incompatible versions of dependencies. It also should not be used as a way of avoiding updating scientific software because it now runs everywhere.\nTerminology  Host - A physical computer running VM/container. Container - An operating system level virtualised environment in which software is installed. Image - A container which has been saved to a file. Hypervisor - The software which runs a virtual machine. Kernel - Core OS components and functions.    Comparisons with Virtual Machines As mentioned before, despite not being virtual machines, containers act like them in many ways.\nHow are containers like VMs?  Isolated environment - Processes run isolated from other processes - they can’t access hardware resources they aren’t allocated. They are independent - Generally you can be given a container image or a virtual machine image and use that to run a piece of software without doing anything else.  How are containers not like VMs?  They use Kernel features of the host - Linux supports process and resource partitioning and isolation (cgroups, OverlayFS, kernel namespacing), which allows containers to use a subset of resources. If you\u0026rsquo;re really interested in the underlying mechanism by which Docker works, have a look here\n VMs require a Hypervisor - The hypervisor is a software based emulation layer for computer hardware and so it is generally slower running software in a VM than natively, even with Intel Vf-X, Sun GridEngine. Free hypervisors slow; commercial ones are expensive! VirtualBox is common free one; VMWare Workstation is a commercial one.\n Generally containers are used in command-line only - With VMs it is very easy to get a full desktop environment. With containers this is more difficult. If we have time, may show a demo of this.\n They take up much less space - Virtual Machines have to bundle the whole operating system, including components which would be the same on the host system. Containers, by virtue of using the host system\u0026rsquo;s kernel (at least on Linux), can therefore take up much less room.\n  Potential Use Cases for Containers as a Scientist Consider the following, which are all valid use cases:\n A new PhD student joins your lab. He isn\u0026rsquo;t an experienced programmer, and setting him up with all of the dependencies will take some time. Using a container means he can get all of the dependencies and a copy of the software working on his computer in minutes.\n An old piece of software runs fine on Ubuntu, but a colleague hasn\u0026rsquo;t been able to install a necessary package because it\u0026rsquo;s not available on Windows which is what he uses.\n You\u0026rsquo;ve just been given an Microsoft Azure Academic Grant, and you now want to run thousands of copies of your research software in the cloud, and you want to avoid a complicated install process.\n You have a data analysis script that chugs away on your desktop for every set of simulation data you produce. However, you run thousands of simulations per week, and the data analysis script takes some time to run. You might install this script into a container, and use that as the basis for running the data analysis on a large cluster.\n  "
},
{
	"uri": "https://scientific-programming.github.io/containers/tutorial1/",
	"title": "Setting up the Software",
	"tags": [],
	"description": "",
	"content": "    For all of the following tutorials, we will use Docker as the container software of choice. How to install Docker varies quite a lot between different operating systems.\nPlease follow the instructions relevant to you:\nWindows  Windows: https://docs.docker.com/docker-for-windows/install/  Note: If you are using Windows 10 Home Edition, please install Docker Toolbox instead.\nMacOS  MacOS: https://docs.docker.com/docker-for-mac/  Linux:  Ubuntu CentOS Debian Fedora  You will probably need to restart your computer as part of the installation process.\n"
},
{
	"uri": "https://scientific-programming.github.io/containers/tutorial2/",
	"title": "Getting Started with Docker",
	"tags": [],
	"description": "",
	"content": " First Steps 1) Make an account on the website https://hub.docker.com\nMake the username something sensible as we\u0026rsquo;ll have to use it soon!\n1) If you haven\u0026rsquo;t already, try \u0026ldquo;docker run ubuntu:18.04\u0026rdquo;. This downloads an image containing Ubuntu 18.04. If it it is the first time you have done this, you should see some output:\nWhat is happening here? Have a look here. Docker Hub is a centralised repository for storing container images, and many are provided for you as a basis for creating your own. So here, we\u0026rsquo;re downloading the Ubuntu 18.04 container image as the starting point for our software.\n2) So, now we want to create our own Docker image and install some software into it. How do we do so?\n Create a directory by doing:  mkdir docker-tutorial  Change directory into the folder:  cd docker-tutorial  Start tracking the files in the folder with bash git init   Create a file called Dockerfile in this directory, and put as the first line:\nfromubuntu:18.04 4) Now, we can start installing things inside the image. We do this by adding subsequent lines to the Dockerfile; a command to run a particular application is prefaced by \u0026ldquo;RUN\u0026rdquo;. If you\u0026rsquo;re not familiar with Linux, and are primarily a Windows or Mac user, it may seem a little odd to install programmes using typed out commands, but it can be very powerful. For Ubuntu, there are basically two commands you need to know.\nFirst, we\u0026rsquo;ll need to get an up to date the list of Ubuntu packages which can be installed; note that this is almost always necessary. To do this, add:\nThe Ubuntu command for doing so is:\napt-get update However, it is not a good idea to add this as an isolated command in Dockerfiles. We\u0026rsquo;ll come to why later.\nTo install programmes in Ubuntu, you run the command:\napt-get install NameOfApplication  To see what applications are available on Ubuntu 18.04, you can have a look https://packages.ubuntu.com/bionic/\nUbuntu Packaging Ubuntu sees a release once every 6 months. However, it\u0026rsquo;s not a good idea to upgrade that frequently. Most scientists using Ubuntu pick a Long Term Stable (LTS) release which is updated about every two years. With a LTS release, software you install through package repositories sees security updates, but not feature updates, and these are provided for three years after release. This means that you can rely on software built in that ecosystem continuing to work.\nIf you need updated versions of packages, you can still do so by either installing it manually, or using Personal Package Archives (PPAs) which are often provided by software authors.\n  First of all, we\u0026rsquo;re just going to install Python 3. The package name for this is just \u0026lsquo;python3\u0026rsquo;\nTo do this, add the following line to your Dockerfile\nRUN apt-get update \u0026amp;\u0026amp; apt-get install -y python3  Breaking this down, we\u0026rsquo;ve just put the two commands together - the \u0026lsquo;\u0026amp;\u0026amp;\u0026rsquo; just runs the two commands as a single command, in order. Note that we\u0026rsquo;ve here added a flag - \u0026lsquo;-y\u0026rsquo; to the install. This just means \u0026lsquo;yes\u0026rsquo; - if we try to install without this flag, the programme apt-get would expect us to confirm that we want to install the software, but the build of the image would fail because we\u0026rsquo;re not in an interactive terminal during the container build process.\nNow, you have a script which tells Docker to build a container which: * Is based on Ubuntu 18.04. You could change this to another Linux distribution if you wanted, such as CentOS. * Contains Python 3.\nThis is the general principle of containers - you build them up in steps until they have everything you need to run real applications.\nNow, we can tell Docker to run a default command when the container is launched. We do this using a slightly different syntax - instead of using RUN, we set a programme using the \u0026lsquo;CMD\u0026rsquo; command.\nCMD /bin/bash  This just tells Docker to launch the Bash shell. From this, we can launch all of the programmes installed into the container. Alternatively, we could just as easily write:\nCMD /usr/local/python3  CMD Warning If you specify multiple commands in a Dockerfile with CMD, then all but the last are ignored!\n  Use the \u0026lsquo;/bin/bash\u0026rsquo; line in your Dockerfile.\n7) Now let\u0026rsquo;s actually build the container image from the script file. We do this using the following command - replace \u0026ldquo;YOURUSERNAME\u0026rdquo; with your username for the account we created with Dockerhub earlier.\ndocker build . -t myimage Breaking this command down:\n Docker is the application.\n We\u0026rsquo;re running Docker\u0026rsquo;s \u0026lsquo;build\u0026rsquo; command\n \u0026rdquo;.\u0026rdquo; refers to the file location - it\u0026rsquo;s saying \u0026ldquo;build the Dockerfile in this folder\u0026rdquo;\n -t myimage - if you\u0026rsquo;re not familiar with Linux, adding a dash is a common way of signalling how to pass information to a command. Here, \u0026ldquo;-t\u0026rdquo; just means build the image with the tag myimage\n  CMD Warning If you ever need help about a particular command, you can add the \u0026lsquo;\u0026ndash;help\u0026rsquo; flag which gives you a bit more information. For example, if we wanted to see what all of the Docker \u0026lsquo;build\u0026rsquo; options were, we can run:\ndocker build --help  and you get a long list of flags and what they mean.\n  More concepts Every time you add another command to the script, you create a new layer. A layer is the essentially just a list of differences between the previous command and the present one. Your container image is built up of multiple layers. If you want to add a new command, you don\u0026rsquo;t have to rebuild completely from scratch - Docker is clever enough to start from the last common layer. These layers do take up storage space, however.\nThat means though, if you change the programmes installed with apt-get on the second line of the script, all subsequent steps must be repeated, because Docker can\u0026rsquo;t work out if subsequent steps are independent or not of each other.\nLooking back\u0026hellip; Earlier we had to specify apt-get update and apt-get install on a single line in our Dockerfile. This is due to the layers; if you try to modify a Dockerfile a few hours or days after creating it, some software may fail to install because Ubuntu sees frequent updates, and the apt package caches stored in the Dockerfile would be out of date. By always prefacing apt-get install with apt-get update we avoid having to worry about this.\n  7) Let\u0026rsquo;s launch a container, and try and run some software.\nWe can do this in two ways - similar but quite different.\n1) Start a container from the image interactively, and launch the programme:\nTo run interactively, we must add the \u0026ldquo;-i -t\u0026rdquo; flag. If we don\u0026rsquo;t do this, the programme will launch, but will freeze!\ndocker run -i -t myimage bash Then, just run\npython3  to launch the Python interpreter.\n2) To create a container from the image, and give it the name \u0026lsquo;mytest\u0026rsquo;\ndocker create --name mytest YOURUSERNAME/myimage  Then, start the container:  docker start --name mytest  Then run a command in that container:  Often, we want to install programmes in the container in order to manage dependencies, but we need to have them act on files stored on the host computer itself. This can easily be achieved by mounting folders into the container, so that they are visible inside it. The syntax for this is:\ndocker run -it -v FOLDER_ON_HOST:FOLDER_IN_CONTAINER myimage  A really common use case is to mount the current directory inside the container. Normally we make the directory inside the container the default working directory for that container. You can do this by adding the following line to your Dockerfile:\nWORKDIR /app  If you\u0026rsquo;re using Linux, we can then mount the current directory on the host system to this folder with:\ndocker run -it -v $(pwd):/app  On Windows this is slightly different:\ndocker run -it -v %cd%:/app  Another common use case is to open make a port from the container visible on the host system.\nWhat is a port? Ports are used to pass messages from one application to another. They are denoted by numbers, and there are two types:\n Transmission Control Protocol (TCP) - Messages sent from one application to another in order. If they arrive in the wrong order they are unjumbled by the reciever and if some are missing because of network issues, the receiver lets the sender know and they are resent. Think of it a bit like having a conversation. UDP - Messages sent from one application to another but no acknowledgemnt from the reciever. Think of it a bit like one application shouting at another.  Ports can be forwarded - think of this like rerouting your post from one address to another.\n  To open a TCP port when running a container you can do it via the command:\ndocker run -it -p 4000:8000 myimage  Here, 4000 is the port on the host machine, and 8000 is the port inside the container which is being forwarded.\nJust to prove this working, create a new file called \u0026lsquo;index.html\u0026rsquo; in your folder with the following contents:\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; Testing out Port Forwarding with Docker \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; Here is some text in a web page. \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Launch the docker container with the following:\n# Linux and Mac docker run -it -p 4000:8000 -v $(pwd):/app myimage python3 -m http.server # Windows docker run -it -p 4000:8000 -v %cd%:/app myimage python3 -m http.server Now, go to the URL localhost:4000 and you should see the webpage!\nUDP Forwarding It\u0026rsquo;s not likely you\u0026rsquo;ll have to use UDP ports very much, but for completeness, the syntax you would use to forward a UDP port is: docker run -it -p 4000:8000/udp\n  "
},
{
	"uri": "https://scientific-programming.github.io/containers/tutorial3/",
	"title": "Saving and Sharing Images",
	"tags": [],
	"description": "",
	"content": " Saving the Container 1) We can save the docker container to a file with\ndocker save myimage \u0026gt; myimage.tar You can load it again with\ndocker load myimage.tar 2) However, it\u0026rsquo;s not normally necessary to save containers like this - much easier just to use Docker Hub. Free uploads of containers if public, one private container per account. Create an account on Dockerhub\nMake a repository called \u0026lsquo;mycontainer\u0026rsquo; on your Dockerhub account.\n3) Now, on your computer, run the command:\ndocker login  You will be prompted for your username and password for Dockerhub. Enter them.\n4) We now need to relabel your image. The format for this needs to match your Dockerhub username:\ndocker tag myimage ryanpepper/myimage Now, we can publish the container online using:\ndocker push ryanpepper/myimage 12) Your container should now be available online. That means, someone else can download it using the docker pull command, and run the same programmes as you in the same way.\n13) Just to prove it to you, let\u0026rsquo;s now delete the containers.\nThere are lots of commands for deleting containers and images - this is quite confusing!\nIf you want to remove everything, you can run:\ndocker system prune Deletes everything that are not associated with a running container - \u0026ldquo;dangling\u0026rdquo;. Add the \u0026ldquo;-a\u0026rdquo; flag to remove additionally any stopped containers and all unused images.\nIf you just want to remove a specific image, you can run\ndocker images This gives a list of all images you\u0026rsquo;ve created, including intermediate layers. Copy the image id (the long string of numbers) of the image you want to remove and run:\ndocker rmi IMAGEID You may need to add the flag \u0026lsquo;-f\u0026rsquo; if you get an error here:\ndocker rmi IMAGEID -f  Note: if other images depend on the image you are deleting, they will also be deleted!\nRemove all images:\ndocker images -a docker rmi $(docker images -a -q) 14) Now pull the image we uploaded:\ndocker pull ryanpepper/myimage  "
},
{
	"uri": "https://scientific-programming.github.io/version-control/",
	"title": "Version Control",
	"tags": [],
	"description": "",
	"content": " What is Version Control? Simply put, it\u0026rsquo;s a way of keeping old versions of your software or documents. If you\u0026rsquo;ve ever worked in a business environment, you might be familiar with Microsoft SharePoint, and the concepts of checking in and out documents. This is an example of version control. Here, however, we\u0026rsquo;re going to teach you how to use Git, which is a more general purpose version control software. There are alternatives (Mercurial and SVN), but Git seems to have become particularly popular with the launch of the site GitHub.\nWhy is it useful? The concept of version control is something which people do without thinking about. It\u0026rsquo;s common to keep older versions of documents in general, and the same applies to code. However, using software to do this for code is not very common in academia, and most people end up with situations something like that in the above comic.\nThink about how you might behave when you find a bug in your code somewhere. You might know that it didn\u0026rsquo;t previously exist and so an older version of a function was fine. With your code tracked in version control, you can look back at old versions of your code, with notes about what changes were made between versions.\nHow is it useful for scientists in particular? There are a number of really strong arguments for using version control as a scientist. When you run a simulation for example, it is good practice to be able to record the exact version of the code used to generate your results. If you don\u0026rsquo;t do so, and you find at a later date that you can\u0026rsquo;t reproduce your simulation results, you can then go back to the old version and find out why this might be the case.\nVersion control is useful especially for writing papers when you have multiple collaborators. When this is the case, you can have a master copy of a document written in LaTeX, which every person can work on together. Certain commands let you see which author wrote or edited each line, and so you know exactly who is responsible for particular changes, making it easy to ask for clarification or make suggestions to the right person as necessary.\n"
},
{
	"uri": "https://scientific-programming.github.io/version-control/tutorial1/",
	"title": "Getting Started",
	"tags": [],
	"description": "",
	"content": " Getting Started with Version Control We\u0026rsquo;re going to use the software Git. It\u0026rsquo;s not really important to know how it works underneath. This comic is actually surprisingly accurate, although we\u0026rsquo;ll try to teach you how to avoid having to do any deleting\u0026hellip;\n1) Open your terminal, or Git Bash if you\u0026rsquo;re using Windows.\n2) Set your name and username with Git. This labels modifications to files you do and associates them with you!\ngit config --global user.name \u0026#34;Ryan Pepper\u0026#34; git config --global user.email \u0026#34;ryan.pepper@soton.ac.uk\u0026#34; 3) Set your favourite text editor by running the appropriate command below:\n# Atom git config --global core.editor \u0026#34;atom --wait\u0026#34; # nano git config --global core.editor \u0026#34;nano -w\u0026#34; # Sublime Text (Mac) git config --global core.editor \u0026#34;/Applications/Sublime\\ Text.app/Contents/SharedSupport/bin/subl -n -w\u0026#34; # Sublime Text (Win, 64-bit install) git config --global core.editor \u0026#34;\u0026#39;c:/program files/sublime text 3/sublime_text.exe\u0026#39; -w\u0026#34; # Notepad++ (Win, 64-bit install) git config --global core.editor \u0026#34;\u0026#39;c:/program files/Notepad++/notepad++.exe\u0026#39; -multiInst -notabbar -nosession -noPlugin\u0026#34; # Emacs git config --global core.editor \u0026#34;emacs\u0026#34; # Vim git config --global core.editor \u0026#34;vim\u0026#34; 4) We\u0026rsquo;re going to create a folder with the command \u0026ldquo;mkdir\u0026rdquo;, and change into that directory with \u0026ldquo;cd\u0026rdquo;.\ncd ~ mkdir project cd project 5) Now, we make the folder into a git repository. This means that git will start to keep track of files created in the folder.\ngit init 6) The command \u0026ldquo;ls\u0026rdquo; shows the directories contents. If we use the command \u0026ldquo;ls -a\u0026rdquo; - the \u0026ldquo;-a\u0026rdquo; flag means that we see hidden files, shows us that a new folder called \u0026ldquo;.git\u0026rdquo; has been created.\n7) We can run\ngit status to show that everything has worked correctly. You should see something like the following:\n# On branch master  #  # Initial commit  # nothing to commit  (create/copy files and use \u0026#34;git add\u0026#34; to track) Git status is a really useful command which gives you information about the \u0026lsquo;state\u0026rsquo; you are currently in.\n8) Let\u0026rsquo;s create a file; open the text editor you chose earlier, and save a file called \u0026ldquo;workshop.txt\u0026rdquo; in the directory you\u0026rsquo;re in.\nWrite something in the file, such as:\nI\u0026#39;m learning how to use Version Control with Git! and save it.\n9) Now, let\u0026rsquo;s try running \u0026lsquo;git status\u0026rsquo; again. What you should see is that now, changes you\u0026rsquo;ve made show up. As of yet, the changes you have made are not saved.\nOn branch master No commits yet Untracked files: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed) workshop.txt nothing added to commit but untracked files present (use \u0026#34;git add\u0026#34; to track) An untracked file is just a file that we haven\u0026rsquo;t told Git to watch in any way - it is completely ignored. To track the file we created, we use the command:\ngit add workshop.txt Running the command \u0026ldquo;git status\u0026rdquo; again:\nOn branch master No commits yet Changes to be committed: (use \u0026#34;git rm --cached \u0026lt;file\u0026gt;...\u0026#34; to unstage) new file: workshop.txt 10) Now, we\u0026rsquo;re going to \u0026lsquo;commit\u0026rsquo; our changes - basically, take a snapshot of them at this particular time.\nYou have two options\ni) Run the command\ngit commit This will bring up the text editor you chose earlier. Type a message about the changes you have made so that the file looks something like this:\nAdded text to workshop.txt Now save the file.\nii) Alternatively, skip opening the text editor with:\ngit commit -m \u0026ldquo;Added text to workshop.txt\u0026rdquo;\nPersonally, this is my preferred way of doing it as it\u0026rsquo;s a bit quicker.\nCommit Messages It\u0026rsquo;s really worth trying to use informative commit messages. It helps you if you need to come back later and work out what changes you made at a previous date. If you\u0026rsquo;re collaborating with multiple people, it\u0026rsquo;s much quicker for them to read your informative commit messages than it is for them to read your code!\n  11) Now make some more changes - add another line of text to the file workshop.txt, and commit them again.\n12) Now we\u0026rsquo;re going to look at the record we\u0026rsquo;ve made so far. Try running the command:\ngit log What you should see is something like the following:\ncommit 3ef8ea1e42fc071b8f8121ba80419b9df6f5d983 (HEAD -\u0026gt; master) Author: Ryan Pepper \u0026lt;ryan.pepper@soton.ac.uk\u0026gt; Date: Wed Oct 24 15:04:12 2018 +0100 Added more text to workshop.txt commit dc6b701bcdbff38fa8a9800f8173f88d514090ac Author: Ryan Pepper \u0026lt;ryan.pepper@soton.ac.uk\u0026gt; Date: Wed Oct 24 14:17:36 2018 +0100 Add text to workshop.txt Breaking this down - there are two sections, for the two commits you\u0026rsquo;ve made so far, ordered from newest to oldest.\nThe big long strings are a label for a particular set of changes. Author and date are self-explanatory, and the text below that is the message\n13) Now, let\u0026rsquo;s say that you need to go back in time and look at how the file looked some time ago. We could just delete the text, but in more complicated cases, that\u0026rsquo;s not sufficient. There is an easy way to go back.\nCopy about 10 or so of the first letters and numbers of the commit that you want to see. Then run the command:\ngit checkout dc6b701bcdbff You will see some output:\nNote: checking out \u0026#39;dc6b701bcdbff38f\u0026#39;. You are in \u0026#39;detached HEAD\u0026#39; state. You can look around, make experimental changes and commit them, and you can discard any changes you make in this state without impacting anything. You\u0026rsquo;re now in a working environment with the old set of changes - if you open the file again, you can see the latest committed changes have disappeared. Don\u0026rsquo;t worry! They\u0026rsquo;re safe. You\u0026rsquo;re in something called a \u0026lsquo;detached HEAD\u0026rsquo; state. This is often a source of a lot of confusion for people new to Git, because if you make commits in this state, they will get lost. In order to learn what this means, we\u0026rsquo;ll need to understand about branches.\nBranches Now is a good time to introduce the concept of a branch. Branches are basically a parallel stream of commits that you can work on separately, and switch to at any time. The branch you are on by default is known as the \u0026ldquo;master\u0026rdquo; branch. You can have as many branches as you like in a repository, and they can act as a really useful place to work on adding a new feature to the code, or fixing a bug. They act like a parallel stream of commits, and can split off from the master branch at any point.\n   Each circle here represents a commit. At a particular commit, you can split off and create a new branch of work while other people work on the master branch. Then, later, you can merge your work back into the master branch.   As mentioned before, when you are in detached HEAD state, anything you do is discarded. However, you can keep changes you make here if you create a new branch like so:\ngit checkout -b mynewbranch HEAD is now at dc6b701 Add text to workshop.txt This is a two stage process. Git checkout is for switching between branches; the \u0026ldquo;-b\u0026rdquo; flag creates new ones.\nIf at any point you need to see a list of all of your branches, you can just run:\ngit branch  And you should see some output like:\n master * mynewbranch  The star here just indicates which branch you are currently working on.\n15) From here, we can make changes. Add some more text in the file workshop.txt and commit the changes.\nYou can switch back to the original history by running the command:\ngit checkout master 16) Now you can try and merge the changes you made in the \u0026lsquo;mynewbranch\u0026rsquo; branch back into the \u0026lsquo;master\u0026rsquo; branch. To do this, make sure you\u0026rsquo;re in the master branch and then run the command:\ngit merge mybranch However, you may see an error message:\nAuto-merging workshop.txt CONFLICT (content): Merge conflict in workshop.txt Automatic merge failed; fix conflicts and then commit the result.  What this means is that Git cannot automatically reconcile the differences between the version of the file in your new branch, and the version of the file in your master branch. This is called a \u0026lsquo;merge conflict\u0026rsquo; That means you manually need to edit the file. Edit the file and you will see three odd lines with special markers:\nHello, we've got a file in here! \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; HEAD Added a line of text on the branch! ======= Added another line to the file. \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; mybranch  The \u0026ldquo;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; HEAD\u0026rdquo; means that what follows is text on the head of the current branch - i.e. mynewbranch.\nThe \u0026ldquo;=======\u0026rdquo; acts as a separator\nThe \u0026ldquo;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; master\u0026rdquo; signals the end of the conflicting changes on the master branch.\nTo reconcile, simply delete these three lines, to make a definitive version of the file, and save it.\nHello, we've got a file in here! Adding a line of text. Adding another line of text.  Do a \u0026lsquo;git add\u0026rsquo; and then \u0026lsquo;git commit\u0026rsquo;.\nPractically working in branches When working in branches, it\u0026rsquo;s really useful to keep merging in the master branch into your feature branch every so often, so that the code doesn\u0026rsquo;t diverge too much. It\u0026rsquo;s much harder to merge a single large change than it is many small ones.\nIt depends on how rapidly the project you are working on is changing, but merging every couple of days is probably a good rule of thumb.\n  "
},
{
	"uri": "https://scientific-programming.github.io/version-control/tutorial2/",
	"title": "GitHub and Collaborating",
	"tags": [],
	"description": "",
	"content": " Storing your repository somewhere safe You have a history of your changes locally, but that\u0026rsquo;s not much good if your hard drive fails. We\u0026rsquo;ll now show you how keep a history remotely.\nGit is known as a \u0026lsquo;distributed version control\u0026rsquo; system. Generally, you host a repository somewhere online. There are lots of different providers for this.\nVersion Control Websites GitHub - free! Now owned by Microsoft. Lots of integrations with other services. Limited number of private repositories, but you gain education status to get an unlimited number. Probably the widest used, and has best social features because of this.\nGitLab - also free. Unlimited number of private repositories. Also allows local hosting - for e.g. in the University of Southampton, there is a private GitLab instance hosted internally, which can be used for sensitive projects.\nBitBucket - Owners Atlassian have a lot of commercial products that are used in industry such as JIRA which integrate well with this service.\n  For this exercise, we\u0026rsquo;ll use GitHub, but in practice there is not much between them.\n1) Create an account on https://www.github.com\n2) Once done, click the \u0026ldquo;+\u0026rdquo; arrow in the top right hand corner, and click \u0026ldquo;New repository\u0026rdquo;\n3) Type in a name and description for your repository:\nDon\u0026rsquo;t touch the other settings yet!\n4) You\u0026rsquo;ll now get a page with a list of commands to type; the ones you want are:\ngit remote add origin https://github.com/rpep/my-new-repository.git git push -u origin master the other options are used when you have not yet created a repository on your local machine.\nWhen you run \u0026lsquo;git push\u0026rsquo;, you will be asked for your username and password for GitHub - enter these.\nNow refresh the page, and you\u0026rsquo;ll see the repository you were working on has appeared online!\nCollaborating - Partner Up 1) Now - in pairs - each go to the Git repository of your neighbour. This will be\nhttps://github.com/their-username/their-repository-name\nClick \u0026lsquo;Fork\u0026rsquo;. This will make a copy of their repository on your GitHub.\n5) Now, copy their repository to your computer with the command:\ncd .. git clone https://github.com/yourusername/their-repository-name.git Cloning to an alternate folder You can only clone a repository like this from GitHub if a folder by the same name doesn\u0026rsquo;t exist in the directory where you are working. You can get around this via:\ngit clone https://github.com/yourusername/their-repository-name.git my-alternate-folder-name  6) Move into the folder:\ncd their-repository-name And make your own change to the file.\n7) Commit it as before:\ngit commit -m \u0026#34;Making a change to my partner\u0026#39;s repository\u0026#34; 8) Now push the change online:\ngit push 9) Go back to GitHub.\nClick \u0026ldquo;New Pull Request, and then \u0026ldquo;Create New Pull Request\u0026rdquo; on the next page.\nAdd in some information about the changes you made, and then \u0026ldquo;Create pull request\u0026rdquo;\n10) Now, each of you go back to your own version of the repository, and look at the tab labelled \u0026ldquo;Pull Requests\u0026rdquo;\nScroll to the bottom, and then press \u0026ldquo;Merge pull request\u0026rdquo;\n12) Pull these changes to your repository using \u0026lsquo;git pull\u0026rsquo;, and your partners changes will now be on your computer as well.\nIf you choose to make your code public, there are a number of files that are an absolute must have. These are normally written in Markdown format (.md).\n A License - A license just describes the terms under which others can use your code. There are many types of Open Source licence, but common ones for academic projects, the GNU GPL and LGPL, MIT, Apache and 3-clause BSD licenses are some common ones.\n A README.\n  "
},
{
	"uri": "https://scientific-programming.github.io/version-control/tutorial3/",
	"title": "Discarding Temporary Changes",
	"tags": [],
	"description": "",
	"content": " Discarding channges 1) If you make some changes to the file workshop.txt, but then decide that they weren\u0026rsquo;t correct or were unnecessary, you can easily get back to the head of the branch with the following command:\ngit reset HEAD workshop.txt This permanently discards these changes!\nResetting the whole repository If you have multiple files that have been changed, and you want to reset all of them, you can use:\ngit reset --hard HEAD Use with caution!\n  2) Alternatively, if you want to hide the changes now, but might come back to them, you can use:\ngit stash This creates a list of changes which are stored, but not committed, and which you can recover later. You can stash multiple times. Change your file and then stash it, and then repeat that again a few times.\n3) To look at a list of the stashes you\u0026rsquo;ve made, just type:\ngit stash list 4) To recover the most recent set of changes, you can just type\ngit stash apply If you want a different set, you can type:\ngit stash apply stash@{2} If there is a clash between your current commit and the stashed code, you will get a merge conflict which you\u0026rsquo;ll need to resolve.\n5) If you recover something from a stash, but then decide you don\u0026rsquo;t want it anymore, you can achieve this by \u0026lsquo;unapplying\u0026rsquo; the stash, using the following command:\ngit stash show -p stash@{2}| git apply -R If you don\u0026rsquo;t specify which stash from the list you recovered from, git will just assume you chose the most recent one.\n"
},
{
	"uri": "https://scientific-programming.github.io/documentation/",
	"title": "Documentation",
	"tags": [],
	"description": "",
	"content": " What makes good documentation on a software project? Nothing can frustrate a user more than coming across a project which has inadequate documentation; without a knowledge of the underpinnings of a software library, the user must either field questions to the authors if they, indeed, are able to take them, or begin to study the source code in detail. This, however, causes many problems. Perhaps the user has no expertise in the area they wish to look at, and the source code is beyond their understanding. It may be that they get so frustrated that they begin to reimplement parts of a library themselves, to avoid having to work with code that they have not written. A piece of software may provide the most elegant solutions in the world for a particular problem, but if users find that they are unable to work with it through a lack of understanding about what the constituent parts do, it is unlikely to see much uptake.\nWhat makes good documentation? There are broadly two types of documentation for software libraries:\n API Documentation - This describes all of the functions that are usable, specifying the input arguments, the behaviour of the function and the return values.\n Examples - Providing examples in context, which show how to use the particular functions, showing particular input values explicitly and what the results are.\n  In general, the best software documentation contains both detailed documentation of the API and examples along with it. Why is this the case?\nIf you want to quickly use a library, and know roughly what you\u0026rsquo;re looking for, examples are normally the quickest way to get started. On the other hand, if you need to use more sophisticated features of a library, you\u0026rsquo;re likely to need the API documentation, because it gives more details of the \u0026lsquo;advanced\u0026rsquo; features. A good rule of thumb when writing documentation is that examples should try and show \u0026lsquo;enough\u0026rsquo; - if there are any pitfalls that might be non-obvious, it\u0026rsquo;s better to point these out and save users any pain.\nPerhaps the best way to learn what software documentation should look like is the use and study of projects which are well documented. We\u0026rsquo;ll look here at an example from the the Python library SciPy.\nNewton Raphson documentation Consider the Newton-Raphson algorithm we used as an example in the testing section of these tutorials. The iterative procedure for finding the root of a function is given by:\n$$ x_{n+1} = x_{n} - \\frac{f(x_n)}{f\u0026rsquo;(x_n)} $$\nBecause this is such a ubiquitous method, it\u0026rsquo;s a good one for us to consider when looking at documentation.\nLet\u0026rsquo;s take a look at the SciPy documentation for this function. The descriptions of the parameters in the whole of the SciPy library (and also the NumPy library) are written to a set of standards. These standards are defined in the documentation here, and they are worth a read to anyone writing software as they are something of a gold standard. Indeed, many other Python projects implement documentation in the same format as these libraries. Here we\u0026rsquo;ll just discuss briefly the main features:\nWe can see first that it starts first with the function signature (i.e. the input arguments), and both a brief and long form description:\nscipy.optimize.newton(func, x0, fprime=None, args=(), tol=1.48e-08, maxiter=50, fprime2=None) Find a zero using the Newton-Raphson or secant method. Find a zero of the function func given a nearby starting point x0. The Newton-Raphson method is used if the derivative fprime of func is provided, otherwise the secant method is used. If the second order derivative fprime2 of func is provided, then Halley’s method is used.  The function signature tells us the input arguments, but without some thought, it would still be difficult to immediately use the function. The description tells us the key information about the particular function, and a bit of brief clarifying information about the function. The key parts, however, are really what follow:\n Parameters: func : function The function whose zero is wanted. It must be a function of a single variable of the form f(x,a,b,c…), where a,b,c… are extra arguments that can be passed in the args parameter. x0 : float An initial estimate of the zero that should be somewhere near the actual zero. fprime : function, optional The derivative of the function when available and convenient. If it is None (default), then the secant method is used. args : tuple, optional Extra arguments to be used in the function call. tol : float, optional The allowable error of the zero value. maxiter : int, optional Maximum number of iterations. fprime2 : function, optional The second order derivative of the function when available and convenient. If it is None (default), then the normal Newton-Raphson or the secant method is used. If it is not None, then Halley’s method is used. Returns: zero : float Estimated location where function is zero.  Each input and output parameter has its type specified - especially necessary in Python given that it is a dynamically-typed language. Some parameters, which are optional, are stated as such. We note that the default values for the optional arguments were given above in the function signature. Then, following each parameter is a description of the input parameters.\nFollowing these, examples are given on how to use the function:\n\u0026gt;\u0026gt;\u0026gt; def f(x): ... return (x**3 - 1) # only one real root at x = 1 \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; from scipy import optimize # fprime not provided, use secant method \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; root = optimize.newton(f, 1.5) \u0026gt;\u0026gt;\u0026gt; root 1.0000000000000016 \u0026gt;\u0026gt;\u0026gt; root = optimize.newton(f, 1.5, fprime2=lambda x: 6 * x) \u0026gt;\u0026gt;\u0026gt; root 1.0000000000000016 # Only fprime provided, use Newton Raphson method \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; root = optimize.newton(f, 1.5, fprime=lambda x: 3 * x**2) \u0026gt;\u0026gt;\u0026gt; root 1.0 # Both fprime2 and fprime provided, use Halley’s method \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; root = optimize.newton(f, 1.5, fprime=lambda x: 3 * x**2, ... fprime2=lambda x: 6 * x) \u0026gt;\u0026gt;\u0026gt; root 1.0 Note that several different perturbations of the input arguments are given. For most people, it would be enough to briefly look at the examples here, and they would immediately be able to get started with using the code.\nWhat\u0026rsquo;s particularly invaluable here is that both the function API documentation and the examples are given in the same place. This makes it quick to get started with using the code. In contrast, many software libraries provide examples and the API, but separate from each other.\n"
},
{
	"uri": "https://scientific-programming.github.io/testing/",
	"title": "Testing Scientific Code",
	"tags": [],
	"description": "",
	"content": " What is a software test? Software tests are written in order to check that the implementation of software is correct, and to guard against dangerous behaviour. They\u0026rsquo;re used to make software run in a safer manner; if we know what the inputs and outputs of sofware should be, and we know that for those inputs the answer is correct, we can have some confidence that the software is correct.\nWhy is this important? Consider how science works in experimental science. We try and apply the scientific method:\nScientific Method A set of rough principles:\n Ask a question. Form a hypothesis. Make a prediction based on the hypothesis. Design an experiment to test the hypothesis. Build the equipment Calibrate equipment by testing it Run the experiment Detail carefully the procedures and record information. Draw conclusions from results.    Consider whether, when writing software to do science, you check that your \u0026lsquo;equipment\u0026rsquo; is calibrated? In many cases, the answer will be no.\nWhy might this be the case? Often ad-hoc changes are made to code which mean things stop working. Have you ever come back to a script that you wrote and found it no longer works because you changed a file somewhere else? These issues become especially common when multiple people, who might not have oversight over what you are using it for, are working on software. It\u0026rsquo;s important to test the relevant parts of your code.\nIn this tutorial, we\u0026rsquo;ll step through some examples in the Python language which aim to show how you can write tests, and incorporate them into your own software in practice.\nPrinciples of Software Testing  Software must meet the requirements. Software must respond correctly to different inputs. Software must run in a reasonable amount of time. Can be installed and run in the intended environment. If running simulations, then the behaviour should make sense.  Static vs Dynamic Testing Static Testing  Reviews - Reviewing the code manually as a group - check for correctness. Walthrough - Parties go through a products specification to give feedback on potential defects. Verification of design  Dynamic Testing  Executing portions of the code and checking the response. Validation of design  Why is it difficult for science?  Much of the time you don’t know what the results will be. Realistic problems can take time to run. Testing requires computation of aggregate statistics.  Why is it crucial for science?  Often need to implement new algorithms or change things. Changing without testing will break things. You might need to come back to a previous experiment to use it as the basis for a new one; if the code is broken, you will have issues!  Dynamic Testing: Types of Test Unit Tests  Code is written in small, independent functions Each function has tests that check that the result makes sense For e.g. a test of a function that calculates sin could check:  $$\\sin{\\left(n\\pi\\right)} = 0 \\,\\,\\,\\,\\, \\forall n \\in \\mathbb{Z}$$\nIntegration Tests  Tests check that the system as a whole works convincingly. For e.g. for a simulation, a single integration test would check that the inputs to the simulation are correctly processed, the simulation proceeds without any errors, and that the results make sense. Multiple integration tests are necessary for a large simulation package, such that all of the different potential combinations of algorithms are constructed. Much, much harder to design, but essential - can be written so that they also serve as examples of how to use the software.  Regression Tests  Check that results don’t get less accurate over time. Check that performance stays the same or gets better over time.  Aside: Test Driven Development Methodology for testing where tests are written before writing any code.\nThis means that\u0026hellip;\n Before writing any code you need to plan out what the interface should be (i.e. what arguments get passed to functions). You must work out what the output should be before writing any code. Can form part of the ’agile’ methodology for software development. Can be difficult for developing scientific code where answers can be difficult to determine in advance.  "
},
{
	"uri": "https://scientific-programming.github.io/documentation/generating-docs/",
	"title": "Documenting Code",
	"tags": [],
	"description": "",
	"content": " Writing some documentation There are a number of different tools for automatically generating documentation for different languages. For Python, a common tool is Sphinx. For projects which combine several languages, sometimes the tool Doxygen is preferred.\nHere, we\u0026rsquo;ll focus on Sphinx, but generally all tools work by similar principles; the source code of a library is parsed, and the author of code annotates it in order to provide the documentation.\nIn Python, we can document a function with a documentation string, or \u0026lsquo;docstring.\u0026rsquo; These are provided as a multi-line string just under the function signature in the source code.\nConsider our simple \u0026lsquo;squared\u0026rsquo; and \u0026lsquo;power\u0026rsquo; functions from the testing tutorial:\ndef squared(x): return x * x def power(x, n): return x ** n An annotated version of \u0026lsquo;squared\u0026rsquo;, using the NumPy documentation standard, could be:\ndef squared(x): \u0026#34;\u0026#34;\u0026#34; Returns the square of the input x Parameters: ----------- x, float: Base number Returns: -------- float: Base number raised to power 2 See Also: ------ pow : raise an argument to an arbitrary power Examples -------- \u0026gt;\u0026gt;\u0026gt; squared(2) 4 \u0026gt;\u0026gt;\u0026gt; squared(8) 64 \u0026gt;\u0026gt; squared(-1) 1 \u0026#34;\u0026#34;\u0026#34; return x*x This might seem verbose, but, everything that\u0026rsquo;s needed is there.\nAccessing the documentation from Python Accessing Documentation from Python If you\u0026rsquo;re in a Python interpreter, you can access the documentation by calling the help function with the name of the function or class you\u0026rsquo;re interested in:\n\u0026gt;\u0026gt;\u0026gt; help(function_name)  "
},
{
	"uri": "https://scientific-programming.github.io/testing/simple-tests/",
	"title": "Writing Simple Tests",
	"tags": [],
	"description": "",
	"content": " Set up Create a folder for this lecture:\nmkdir python-testing cd python-testing-tutorial git init  For this workshop, build the following Dockerfile, and label it \u0026lsquo;testing\u0026rsquo;. Pip is a package manager for Python; using it, we can install Python libraries. We\u0026rsquo;ll install the following:\nfromubuntu:18.04RUN apt-get update \u0026amp;\u0026amp; apt-get install -y python3 python3-pipRUN pip install numpy matplotlibWORKDIR/app Starting off simply: Squaring a number (a pathological example\u0026hellip;) def squared(x): return x*x  Consider just squaring a number. This is so simple, it wouldn\u0026rsquo;t really be tested in a real piece of software, but we\u0026rsquo;ll show it here just as an example of how to do it. What could we check?\n Do we get the correct answer for positive numbers? Do we get the correct answer for negative numbers? Do the input arguments make sense?  It\u0026rsquo;s clear that all of these would be sensible, but considering it carefully, it shows immediately the difficulty of actually applying testing in practice. There are an infinite amount of numerical input arguments - we cannot reasonably test them all.\nHow can we therefore reduce it down to a more manageable set of tests? We by necessity have to restrict our tests to a subset of all of the possible outcomes, and have to exercise some thought.\nIn Python, we can write tests using the Pytest framework. Pytest goes through all of the files in a directory with a \u0026ldquo;.py\u0026rdquo; file extension, and looks for normal Python functions which have names that start with \u0026ldquo;test\u0026rdquo;. It then runs all of these functions in sequence.\nIn general, it\u0026rsquo;s a good idea to write tests in a separate file to the function implementation.\nSo, to keep track of what we\u0026rsquo;re doing, we\u0026rsquo;ll create a new folder and a new Git repository:\nIn this folder, we\u0026rsquo;ll create \u0026lsquo;functions.py\u0026rsquo; and \u0026lsquo;test_functions.py\u0026rsquo;\nIn functions.py add the function from above.\nNow, in test_functions.py, we\u0026rsquo;ll write a test. As mentioned before, you write a normal Python function. However, we use something that you may not have seen before - the assert statement. Asserts just check that something is true; for example:\nx = 2 assert x**2 == 4 If you need to, you can provide an error message if an assertion fails:\nassert 2 == 1, \u0026#34;The number 2 does not equal 1...\u0026#34; Add the following function to test_functions.py:\ndef test_square_positive_integers(): assert square(1) == 1 # Note the mistake here! We\u0026#39;ll leave this here to # show what happens when a test fails. assert square(2) == 8 assert square(4) == 16 assert square(100) == 10000 Now, using our Docker knowledge from before, we\u0026rsquo;re going to run this test with Python from a container. Create a Dockerfile with the following contents:\nfromubuntu:18.04RUN apt-get updateRUN apt-get install -y python3RUN pip3 install pytestWORKDIR/io Here, we\u0026rsquo;re using Pip, the Python package installer to install the Python package pytest.\nBuild the container:\ndocker build . -t python-testing Now, we can run the tests with:\ndocker run -v$(pwd):/io python-testing pytest -v . You should see output something like this:\n============================= test session starts ============================== platform linux -- Python 3.6.6, pytest-3.9.2, py-1.7.0, pluggy-0.8.0 -- /usr/bin/python3 cachedir: .pytest_cache rootdir: /io, inifile: collecting ... collected 1 item test_functions.py::test_square_positive_integers FAILED [100%] =================================== FAILURES =================================== ________________________ test_square_positive_integers _________________________ def test_square_positive_integers(): assert square(1) == 1 # Note the mistake here! We\u0026#39;ll leave this here to  # show what happens when a test fails. \u0026gt; assert square(2) == 8 E assert 4 == 8 E + where 4 = square(2) test_functions.py:10: AssertionError =========================== 1 failed in 0.16 seconds =========================== Note now, that we can see that a test has failed where we introduced the error in the test. We can now correct the test so that it\u0026rsquo;s expecting the correct answer:\ndef test_square_positive_integers(): assert square(1) == 1 assert square(2) == 4 assert square(4) == 16 assert square(100) == 10000 Now if we rerun pytest, we see something different:\n============================= test session starts ============================== platform linux -- Python 3.6.6, pytest-3.9.2, py-1.7.0, pluggy-0.8.0 -- /usr/bin/python3 cachedir: .pytest_cache rootdir: /io, inifile: collecting ... collected 1 item test_functions.py::test_square_positive_integers PASSED [100%] =========================== 1 passed in 0.21 seconds =========================== As many tests as are necessary can be written.\n{{ panel theme=\u0026ldquo;warning\u0026rdquo; title=\u0026ldquo;Exercise: Normalising a vector.\u0026rdquo; }}\nConsider as a really simple example, a function which normalises a vector. We\u0026rsquo;re going to start and thing about how it should work.\nIf there are n elements in a vector, the norm is given by: $$\\sqrt{x_1^2 + x_2^2 + x_3^2 + x_4^2 + \\cdots + x_n^2}$$\nVarious appropriate tests of this could check the results:\n If we pass an array full of integers or floating point numbers. If we pass an array which is full of zeros.  Write a test for each of these cases for a function with the function signature:\ndef normalise(v): Then, implement the normalise function and see if your tests pass!\nNote: To create an array in Python, you can use the following syntax:\n\u0026gt;\u0026gt;\u0026gt; import numpy as np \u0026gt;\u0026gt;\u0026gt; x = np.array([0.0, 1.0]) # We can perform element-wise operations on NumPy arrays: \u0026gt;\u0026gt;\u0026gt; x / 2 array([0.0, 0.5]) {{ /panel }}\nExceptions Most programming languages have the concept of exceptions. An exception is just a way of dealing erroneous conditions which happen while a programme is running which require special handling. In Python doing this in your own code is really straightforward. For example, when calculating the Coulomb potential in 1-D, we need to make sure that if the input distance is zero, the function raises an error, because the input argument is invalid. We can do this like:\ndef CoulombPotential(r): if (r == 0): raise ValueError(\u0026quot;r cannot equal zero.\u0026quot;) return 1 / abs(r)  Now, when we run this code, if 0 is passed as an input argument:\n\u0026gt;\u0026gt;\u0026gt; CoulombPotential(0) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 3, in CoulombPotential ValueError: r cannot equal zero. Debug Mode Many people do not know that the Python interpreter runs in \u0026lsquo;debug\u0026rsquo; mode by default. When it is disabled, by running Python with the \u0026lsquo;-O\u0026rsquo; flag, all asserts in code are skipped, and the flag \u0026lsquo;debug\u0026rsquo; is set to True. Utilising this can be useful when you want to check code for correctness, but know that some checks you are running can be costly in performance. It can also be used to provide more\ndef square(x): if __debug__: print(\u0026#34;We\u0026#39;re in debug mode!\u0026#34;) assert type(x) in [int, float, complex], \u0026#34;Input argument x is not of a numeric type int, complex or float\u0026#34; return x*x In debug mode, if we run the function, we get the following output:\n\u0026gt;\u0026gt;\u0026gt; square(2) We're in debug mode! 4 \u0026gt;\u0026gt;\u0026gt; square('a') We're in debug mode! Traceback (most recent call last): File \u0026quot;\u0026lt;stdin\u0026gt;\u0026quot;, line 1, in \u0026lt;module\u0026gt; File \u0026quot;\u0026lt;stdin\u0026gt;\u0026quot;, line 4, in square AssertionError: Argument is not of a numeric type  When we instead run \u0026lsquo;python3 -O\u0026rsquo;, we see:\n\u0026gt;\u0026gt;\u0026gt; square(2) 4 \u0026gt;\u0026gt;\u0026gt; square('a') Traceback (most recent call last): File \u0026quot;\u0026lt;stdin\u0026gt;\u0026quot;, line 1, in \u0026lt;module\u0026gt; File \u0026quot;\u0026lt;stdin\u0026gt;\u0026quot;, line 5, in square TypeError: can't multiply sequence by non-int of type 'str'  We can see that the print statement is completely skipped, and instead of our helpful error message which resulted from our check, we get Python\u0026rsquo;s less helpful one.\nC, C++ and FORTRAN Compilers Achieving the same in compiled languages is also straightforward, because a preprocessor runs over the code before the compilation stage when a compiler is invoked. Macros can be used to disable code under certain conditions, and this is widely used to disable costly code paths that diagnose errors, which can be turned on when an issue is noticed. See for example the following code which multiplies two vectors in C++:\nvoid multiply_vector(const std::vector\u0026lt;double\u0026gt; a, double b, std::vector\u0026lt;double\u0026gt; \u0026amp;c) { for(int i = 0; i \u0026lt; a.size(); i++) { c[i] = a[i] * b; #ifdef MYPROJECT_DEBUG  std::cout \u0026lt;\u0026lt; \u0026#34;c[\u0026#34; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; \u0026#34;] = \u0026#34; \u0026lt;\u0026lt; c[i] \u0026lt;\u0026lt; std::endl; #endif  } }  Compiling with g++, you can enable the printing of the array in this function just by passing a flag:\ng++ file.cpp -DMYPROJECT_DEBUG -c  Exercise 2: Lennard-Jones 6-12 potential The Lennard-Jones potential is given by $$ V\\left(r\\right) = \\epsilon \\left[\\left(\\frac{r_m}{r}\\right)^{12} - 2\\left(\\frac{r_m}{r}\\right)^6\\right]$$\n Write a function that takes three numbers - $$\\epsilon$$, $$r_m$$ and $$r$$, and returns this potential. Write a test for this function which checks values against known quantities. Write a test that checks that the function throws a ValueError if numerical arguments are not passed.  "
},
{
	"uri": "https://scientific-programming.github.io/documentation/generating-sphinx/",
	"title": "Generating documentation webpages with Sphinx",
	"tags": [],
	"description": "",
	"content": " Setting up a Python Module 1) Create a new folder called \u0026lsquo;codedocs\u0026rsquo; to work in for this exercise. Change into this folder and \u0026lsquo;git init\u0026rsquo; in it to keep track of files.\n2) In order to document some code, we\u0026rsquo;re going to arrange our Git repository in a common way, so that the code is separate from the documentation. Create a folder called \u0026lsquo;codedocs\u0026rsquo; and create a file called \u0026lsquo;functions.py\u0026rsquo; Create a Python file with the example we showed earlier inside.\ndef squared(x): \u0026#34;\u0026#34;\u0026#34; Returns the square of the input x Longer description - the square is found by multiplying x by x... Parameters: ----------- x, float: Base number Returns: -------- float: Base number raised to power 2 See Also: --------- pow : raise an argument to an arbitrary power Examples -------- \u0026gt;\u0026gt;\u0026gt; squared(2) 4 \u0026gt;\u0026gt;\u0026gt; squared(8) 64 \u0026gt;\u0026gt;\u0026gt; squared(-1) 1 \u0026#34;\u0026#34;\u0026#34; return x*x Add and commit this file to your Git repository.\n4) In order that we can make our Python code importable as a module and use the functions in it directly, create another Python file in the \u0026lsquo;codedocs\u0026rsquo; subdirectory called \u0026lsquo;init.py\u0026rsquo;, with the following content:\nfrom .functions import * 5) With this file layout, we can now use the code in Python. Just to show you, launch a container:\n# Linux and Mac docker run --rm -v $(pwd):/app sphinx python3 # Windows docker run --rm -v %cd%:/app sphinx python3  Now you can import and test out the function:\n\u0026gt;\u0026gt;\u0026gt; import codedocs \u0026gt;\u0026gt;\u0026gt; codedocs.squared(2.0) 4.0 5) We can make the module an installable Python package just by adding a file called setup.py at the root directory of the Git repository:\nfrom distutils.core import setup setup(name=\u0026#39;codedocs\u0026#39;, version=\u0026#39;1.0\u0026#39;, py_modules=[\u0026#39;codedocs\u0026#39;], ) This means that someone can come along and install your repository onto their computer just by running the command:\npip install . inside the folder.\nSetting up Sphinx 1) Put a Dockerfile in the root directory of your repository:\nfromubuntu:18.04RUN apt-get update \u0026amp;\u0026amp; apt-get install -y python3 python3-pipRUN pip3 install numpy matplotlib sphinxWORKDIR/app Add the Dockerfile to your repository and commit it. Build and start the container with:\ndocker build . -t documentation # Linux and Mac docker run -v $(pwd):/app -it documentation # Windows docker run -v %cd%:/app -it documentation 2) Now in the container, we\u0026rsquo;re going to run a configuration application, which sets up everything we need to build documentation from our code. Create a folder, then run the sphinx configuration application. You only ever have to do this once; it\u0026rsquo;s just a quick way of getting what you need to get started.\nmkdir docs sphinx-quickstart docs Sphinx now prompts you with a lot of questions, which set up the generation of documentation. The default suggestion is given in square brackets at the end of the line. To each question, answer it. For most, you can use the default, but some you cannot and must type a response; if there is no text specified after the end colon for the question below, use the default value (just press \u0026lsquo;Enter\u0026rsquo; on your keyboard)\n\u0026gt; Separate source and build directories (y/n) [n]: \u0026gt; Name prefix for templates and static dir [_]: \u0026gt; Project name: My Documentation Example \u0026gt; Author name(s): Ryan Pepper \u0026gt; Project release []: 0.0.1 \u0026gt; Source file suffix [.rst]: \u0026gt; Name of your master document (without suffix) [index]: \u0026gt; Do you want to use the epub builder (y/n) [n]: Indicate which of the following Sphinx extensions should be enabled: \u0026gt; autodoc: automatically insert docstrings from modules (y/n) [n]: y \u0026gt; doctest: automatically test code snippets in doctest blocks (y/n) [n]: y \u0026gt; intersphinx: link between Sphinx documentation of different projects (y/n) [n]: \u0026gt; todo: write \u0026#34;todo\u0026#34; entries that can be shown or hidden on build (y/n) [n]: \u0026gt; coverage: checks for documentation coverage (y/n) [n]: \u0026gt; imgmath: include math, rendered as PNG or SVG images (y/n) [n]: \u0026gt; mathjax: include math, rendered in the browser by MathJax (y/n) [n]: y \u0026gt; ifconfig: conditional inclusion of content based on config values (y/n) [n]: \u0026gt; viewcode: include links to the source code of documented Python objects (y/n) [n]: y \u0026gt; githubpages: create .nojekyll file to publish the document on GitHub pages (y/n) [n]: \u0026gt; Create Makefile? (y/n) [y]: \u0026gt; Create Windows command file? (y/n) [y]: Inside the \u0026lsquo;docs\u0026rsquo; folder, Sphinx has now created several folders and files, which are where documentation gets built.\n3) The file \u0026lsquo;conf.py\u0026rsquo; is just a Python script which contains all of the configuration options you set in the quickstart script, so don\u0026rsquo;t worry if you want to change something. We need to make a few changes to conf.py which mean that we can autogenerate some documentation for the code.\n Change the contents of the section \u0026lsquo;Path Setup\u0026rsquo; to the following:  import os import sys sys.path.insert(0, os.path.abspath(\u0026#39;..\u0026#39;)) These commands make our module \u0026lsquo;codedocs\u0026rsquo; visible to Sphinx, so that it can see all of the source files.\n There is a list of extensions that looks like this:\nextensions = [ \u0026#39;sphinx.ext.autodoc\u0026#39;, \u0026#39;sphinx.ext.doctest\u0026#39;, \u0026#39;sphinx.ext.mathjax\u0026#39;, \u0026#39;sphinx.ext.viewcode\u0026#39;, ] We need to add an extension which makes our nice NumPy documentation work. Do this by adding \u0026lsquo;sphinx.ext.napoleon\u0026rsquo; to this list.\n Just after this, add the lines:\n  napoleon_google_docstring = False doctest_global_setup = \u0026#34;\u0026#34;\u0026#34; from codedocs import * \u0026#34;\u0026#34;\u0026#34; Later, we\u0026rsquo;re going to run something called Doctest. Remember the lines of code we put into the squared function? Doctest runs these and checks that the output is consistent with what we wrote.\n4) We\u0026rsquo;re now done configuring the conf.py, so let\u0026rsquo;s actually generate some files. Sphinx has an application called \u0026lsquo;apidoc\u0026rsquo;. An API (application programme interface) is the defined inputs and outputs of functions in software. We\u0026rsquo;ve already specified these in the function docstring for \u0026lsquo;squared\u0026rsquo;. So all sphinx-apidoc is doing is reading our source code files, and generating \u0026lsquo;rst\u0026rsquo; files from them.\nMaking sure you\u0026rsquo;re in the \u0026lsquo;docs\u0026rsquo; folder in your container, run the following command.\nsphinx-apidoc -o source ../codedocs  Now, we can get a very \u0026lsquo;simple\u0026rsquo; version of our documentation by just running:\nmake html  This turns all of our generated files into HTML files that can be read and displayed by a web browser. Find the folder in your file explorer, and open \u0026lsquo;index.html\u0026rsquo; inside docs/_build/html. You should see a website that looks something like the following; at the moment it does not look like much!\nHowever, have a look around the \u0026lsquo;Module Page\u0026rsquo; - you should be able to spot our module. Clicking it should show us the documentation we wrote for the squared function!\nBroader documentation 1) We can edit the homepage to make it a bit more informative. We\u0026rsquo;ll edit \u0026lsquo;index.rst\u0026rsquo;. This file is written in the ReStructured Text format.\nThis file at the moment should look like this:\n.. codedocs documentation master file, created by sphinx-quickstart on Tue Oct 30 00:05:22 2018. You can adapt this file completely to your liking, but it should at least contain the root `toctree` directive. Welcome to codedocs's documentation! ==================================== .. toctree:: :maxdepth: 2 :caption: Contents: Indices and tables ================== * :ref:`genindex` * :ref:`modindex` * :ref:`search`  Add in some text after the Welcome message like below to describe that we\u0026rsquo;re setting up documentation with Sphinx.\nWelcome to codedocs\u0026#39;s documentation! ==================================== codedocs is an example project that we\u0026#39;re setting up at a workshop on the30th October 2019.What is the point of this? -------------------------- Documentation is crucial to using software!.. toctree:: :maxdepth: 2 :caption: Contents: Save the file, and run \u0026lsquo;make html\u0026rsquo; again, and refresh the page. You can see that the \u0026lsquo;===\u0026rsquo; under a title makes it a page title, and the \u0026lsquo;\u0026mdash;\u0026rsquo; a subtitle. Here, we can see some complex looking stuff called a \u0026lsquo;toctree\u0026rsquo;. This is just a pointer to Sphinx to place the table of contents here.\n3) We\u0026rsquo;re now going to add a new file. Creating tutorials with examples is a good way to build up documentation for large projects.\nFirst, create a file called \u0026lsquo;tutorial.rst\u0026rsquo; and inside it put some contents:\nTutorial! ========= On this page we\u0026#39;re going to do some tutorial stuff!The following few lines are some code... code-block:: python print(\u0026#34;This is some Python code\u0026#34;) At the moment, if we run \u0026lsquo;make html\u0026rsquo;, we wouldn\u0026rsquo;t see a link to it anywhere on the homepage of our site. We need to add our file to the table of contents somewhere! In index.rst, modify the \u0026lsquo;toctree\u0026rsquo; to the following.\n.. toctree:: :maxdepth: 2 :caption: Contents: tutorial  Note the blank line - Sphinx is quite sensitive! It will often fail to build if you miss this. You can add as many things as you like to your web page - just add more rst files, and add them to the toctree. Run make html again and you should see your changes on the webpage.\nHosting the Documentation You\u0026rsquo;ve created a web page full of documentation, but how can you put it online?\nA free ad-powered service called Read The Docs exists exactly for this purpose. It is very easy and quick to set up, if you have your repository set up in the correct format.\n1) Create a repository called codedocs-yoursurname on GitHub and add all of the files (but NOT the _build directory), and push our local repository to it.\n2) Go to Read the Docs, and log in with your GitHub account.\n3) Click \u0026lsquo;Import Repository\u0026rsquo;, and select codedocs.\n4) If the build doesn\u0026rsquo;t start automatically, start the build.\n5) Now go to codedocs-yoursurname.rtfd.org to see your documentation!\n"
},
{
	"uri": "https://scientific-programming.github.io/testing/complex-tests/",
	"title": "Writing More Complex Tests",
	"tags": [],
	"description": "",
	"content": " Convergence Because of the ubiquity of differential equations in physical problems, it\u0026rsquo;s a common exercise to calculate the numerical derivatives of functions via a Central difference formula:\n$$ f\u0026rsquo;(x) = \\frac{f(x + h) - f(x - h)}{2h} + \\mathcal{O}(h^2) $$\nHow can we test this? We\u0026rsquo;ll decide to call our function CentralDiff. First we can think about simple tests that check that an error is raised if input arguments do not make sense. We know what parameters our function will take, so we define an \u0026lsquo;interface\u0026rsquo; to the function:\ndef CentralDiff(func, x, h): \u0026quot;\u0026quot;\u0026quot; Code to be implemented \u0026quot;\u0026quot;\u0026quot; pass  We\u0026rsquo;ll need to pass a function, the x position where the derivative is computed and the step size. Tests of the input arguments are:\nimport numpy as np import pytest def test_inputs_error_raised(): # It does not make sense for h to be exactly zero, so this should raise # an error. with pytest.raises(ValueError): CentralDiff(np.sin, 0.0, 0.0) # If an argument other than a function is passed, a TypeEror should be raised. with pytest.raises(TypeError): CentralDiff(2.0, 0.0, 1e-5) # We check that non-numeric inputs raise a TypeError with pytest.raises(TypeError): CentralDiff(np.sin, \u0026#39;0.0\u0026#39;, 1e-5) with pytest.raises(TypeError): CentralDiff(np.sin, 0.0, \u0026#39;1e-5\u0026#39;) Save the non-implemented function to a file called \u0026lsquo;functions.py\u0026rsquo;, and save the test to test_functions.py\n We can test the function against known derivatives of analytic functions that we calculate by hand.  How would you test the convergence? Write a test which checks the error on the derivative of Sin at a known point for different values of h. What can you check numerically? Write an implementation of the numerical function.\nIf you struggle, it may help first to implement the CentralDiff function and look at the results, and plot the error.\n  ### Exercise: Newton-Raphson The Newton-Raphson algorithm finds minima of functions with the following recursion relation:\n$$ x{n+1} = x{n} - \\frac{f(x_n)}{f\u0026rsquo;(x_n)}\nWe normally check convergence by looking at the difference between the last step and the previous step, and stopping when we reach a tolerance for $$ abs(f(x_n)) \u0026lt; \\epsilon $$\nImplement the algorithm as a function. Write a test that checks this works.\nExercise: Testing ODE Solvers: An integration test How would one go about testing an ODE solver? Consider the prototypical simple 2nd order ODE - the simple harmonic oscillator:\n$$ m \\frac{\\mathrm{d}^2 x}{dt^2} + k x = 0 $$\nWe know from A Level maths that the general solution to this is: $$ x(t) = A \\cos{\\omega t} + B \\sin{\\omega t} $$ with $$\\omega = \\sqrt{k / m} $$\nTo compute the solution numerically, we have to decompose the ODE:\n$$\\frac{\\mathrm{d}v}{\\mathrm{d}t} = \\frac{-kx}{m} $$ $$\\frac{\\mathrm{d}x}{\\mathrm{d}t} = v $$\nWrite a very simple Euler integrator for this problem. Use the initial conditions:\n$$ x(t = 0) = 1.0 $$ $$ v(t = 0) = 0.0 $$\nwith paramters (k = 1) and (m = 1)\nThink about how you would design the interface to this so that it can be generally applied to different problems. We know the analytic solution for this problem, so play around with how the error on the position of a mass increases as you uses. You need to have at least two functions to unit test here!\nHint: Think about both the solution and properties you can compute about the system you\u0026rsquo;re simulating!\n"
},
{
	"uri": "https://scientific-programming.github.io/testing/continuous-integration/",
	"title": "Continuous Integration",
	"tags": [],
	"description": "",
	"content": " Continuous Integration What is Continuous Integration?\n Runs the tests repeatedly, every time you make a change. You use a remote service, to avoid having to run all tests locally - useful if they take some time to run. Generally, CI services send you angry emails when tests fail! It requires you to be using version control, and all tests are run when you push your changes to the remote repository. If you are developing a new feature, tests also get run when you\u0026rsquo;re developing features in a branch/fork.  There are a number of ways to do CI. If you don\u0026rsquo;t have a server, and you\u0026rsquo;re happy for your project to be hosted remotely on GitHub or on another site, you can use remote services such as TravisCI, CircleCI and GitLab. If you have your own server, and you need everything to be private (sometimes this is the case if you\u0026rsquo;re working on academic work with industry partners), then there are services you can host locally such as Jenkins and Buildbot.\nTravisCI We\u0026rsquo;ll here pick this, as it’s easy to set up from what we’ve already done:\nFirst, log in to Travis CI with your GitHub account.\nNow, to build our repository, we\u0026rsquo;ll need to put a very simple Travis configuration file into the root of the Git repository. Create a file called \u0026lsquo;.travis.yml\u0026rsquo;. This is written in a markup language called YAML, but the syntax for this is very simple.\nTravis comes preinstalled with many programming languages, but uses an older version of Ubuntu. Because we have used Docker throughout to run our software, however, we can just use this as the basis on Travis to run our software. We need to specify only a few options, and everything is set up for us:\nsudo: required services: - docker  These options just tell travis that root permissions are needed (a requirement for Docker itself), and we need Docker to be installed.\nWhen Travis builds first start, they clone the latest commit from the Git repository, and then change directory into that folder. So from then on, you can write out commands referring to files in that folder.\nSo now, we want to get the right environment to run our tests. Let\u0026rsquo;s build the Docker container from the Dockerfile in our repository. Add the following lines.\nbefore_install: - docker build . -t build  The before_install section here tells Travis to run the bash command on the subsequent line. This is normally where you run any setup which is needed to run the tests.\nNow, we\u0026rsquo;ve done everything we need to do before running the tests, so let\u0026rsquo;s put in the command to run them. We do this in a \u0026lsquo;script\u0026rsquo; block:\nscript: - docker run -v`pwd`:/io build pytest -v .  The total file should now look like:\nsudo: required services: - docker before_install: - docker build . -t build script: - docker run -v`pwd`:/io build pytest -v .  Stage this file in your Git repository and commit it. Push it to GitHub, then navigate to the Travis website again. You should now see that your repository has appeared, and that a build is in progress. If everything is correct, your Python tests should run remotely!\nClearly, we could have much more complex build processes than this, and you run Python inside the build environment rather than in a Docker container. However, it\u0026rsquo;s in general a good idea to delegate these into a container, as it avoids you having to duplicate the install script in multiple places, and keeps the development environment where you work the same as the test environment.\nWriting a README file One common thing to do is to add a readme file to a GitHub repository. Create a Generally these just give some information for people who come across the project, such as install instructions. These files are typically written in Markdown - a simple syntax which is widely used online in forums and in many other places. A simple README.md, written in Markdown, for this project could be:\n# Functions ![Travis Build Status](https://travis-ci.com/rpep/mytestrepo.svg?branch=master)Writing a simple package. This repository follows the material on https://scientific-programming.github.ioto create a repository with simple Python tests and Continuous Integration set up. The URL here points to my repository on Travis; replace it with the one from yours. You can find this by clicking the following when you are on a repository page on Travis.\n  Workflow A normal workflow for continuous integration is often something like:\n Create a branch or a fork of a repository to work on a new feature. Write some tests, and run ones relevant to the changes you\u0026rsquo;re making on your local machine. Commit changes, and push to the remote repository. If any tests fail, you\u0026rsquo;ll get a notification of this, and you can fix them.  It can also be useful to set up tests to run at periodic intervals - i.e. nightly. This means that if a dependency unexpectedly changes in a repository that you\u0026rsquo;re using, it is picked up as early as possible.\n"
},
{
	"uri": "https://scientific-programming.github.io/cheatsheet/",
	"title": "Command Cheatsheet",
	"tags": [],
	"description": "",
	"content": "The following is a list of standard commands in cmd on Windows or Bash on *nix systems. It\u0026rsquo;s by no means a comprehensive list - these are just to help you\nSometimes the commands I\u0026rsquo;ll show (which are used for navigating around on Linux or Unix based systems like Macs) don\u0026rsquo;t work in Windows. So here, I\u0026rsquo;ve put a list of things you might want to do, and the commands in both Windows and Linux.\n   Concept Windows cmd command Linux     Run a file filenme ./filename   Change directory into folder X cd X cd X   List files dir ls   Show the current directory cd pwd   Copy filenamed A to B copy A B cp A B   Delete file A del A rm A   Delete folder A rmdir A rm -r A   Move file A to B move A B mv A B   Create a folder called A mkdir A mkdir A    "
},
{
	"uri": "https://scientific-programming.github.io/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://scientific-programming.github.io/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]