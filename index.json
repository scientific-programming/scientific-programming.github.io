[
{
	"uri": "https://scientific-programming.github.io/",
	"title": "",
	"tags": [],
	"description": "",
	"content": " Scientific Programming This website aims to be a self contained basics course designed for scientists who need to do some programming as part of their research. The topics covered are:\n Containerisation - How can a team of developers, often working remotely from one another set up a consistent environment for developing their software? If you have ever been sent code by someone and not been able to run it, this section is for you\u0026hellip; We will show you how to configure a container to run a C/C++ or Python application using Docker.\n Version Control - No longer will you have 5 versions of your code in a folder with names like \u0026lsquo;main-working-18-04-2017.cpp\u0026rsquo;, \u0026lsquo;main-not-working-16-08-2018.cpp\u0026rsquo;\u0026hellip; We\u0026rsquo;ll teach how to set up a history of code development using the tool Git.\n Continuous integration and Testing - If you make a change to your code, how do you know that it\u0026rsquo;s not broken? If you\u0026rsquo;ve ever come to use a part of your code and realised that it no longer works because you changed something else, this will be useful to you. We will teach you how to write appropriate tests for scientific codes, and show you how to set up a continuous integration system for Git repositories.\n Documentation - What makes good documentation? At a minimum, what should the requirements be? In this, we\u0026rsquo;ll go through some examples and talk about and show some of the tools for documenting software.\n  "
},
{
	"uri": "https://scientific-programming.github.io/testing/simple-tests/",
	"title": "Writing Simple Tests",
	"tags": [],
	"description": "",
	"content": " Starting off simply: Squaring a number Consider as a really simple example, a function which takes a number and computes the square of that number.\ndef square(x): return x * x Various appropriate tests of this could check:\n Is the correct answer given for positive integers? Is the correct answer given for negative integers? Is the correct answer given for zero? Is the correct answer given for positive and negative decimals? What is the behaviour for complex numbers? How does the function behave when an input argument is not of the type specified is passed in (such as a string)?  It\u0026rsquo;s clear that all of these would be sensible, but considering it carefully, it shows immediately the difficulty of actually applying testing in practice. There are an infinite amount of numerical input arguments - we cannot reasonably test them all.\nHow can we therefore reduce it down to a more manageable set of tests? We by necessity have to restrict our tests to a subset of all of the possible outcomes, and have to exercise some thought.\nIn Python, we can write tests using the Pytest framework. Pytest goes through all of the files in a directory with a \u0026ldquo;.py\u0026rdquo; file extension, and looks for normal Python functions which have names that start with \u0026ldquo;test\u0026rdquo;. It then runs all of these functions in sequence.\nIn general, it\u0026rsquo;s a good idea to write tests in a separate file to the function implementation.\nSo, to keep track of what we\u0026rsquo;re doing, we\u0026rsquo;ll create a new folder and a new Git repository:\nmkdir python-testing-tutorial cd python-testing-tutorial git init  In this folder, we\u0026rsquo;ll create \u0026lsquo;functions.py\u0026rsquo; and \u0026lsquo;test_functions.py\u0026rsquo;\nIn functions.py add the function from above.\nNow, in test_functions.py, we\u0026rsquo;ll write a test. As mentioned before, you write a normal Python function. However, we use something that you may not have seen before - the assert statement:\ndef test_square_positive_integers(): assert square(1) == 1 # Note the mistake here! We\u0026#39;ll leave this here to # show what happens when a test fails. assert square(2) == 8 assert square(4) == 16 assert square(100) == 10000 Now, using our Docker knowledge from before, we\u0026rsquo;re going to run this test with Python from a container. Create a Dockerfile with the following contents:\nfromubuntu:18.04RUN apt-get updateRUN apt-get install -y python3RUN pip3 install pytestWORKDIR/io Here, we\u0026rsquo;re using Pip, the Python package installer to install the Python package pytest.\nBuild the container:\ndocker build . -t python-testing Now, we can run the tests with:\ndocker run -v`pwd`:/io python-testing pytest -v . You should see output something like this:\n============================= test session starts ============================== platform linux -- Python 3.6.6, pytest-3.9.2, py-1.7.0, pluggy-0.8.0 -- /usr/bin/python3 cachedir: .pytest_cache rootdir: /io, inifile: collecting ... collected 1 item test_functions.py::test_square_positive_integers FAILED [100%] =================================== FAILURES =================================== ________________________ test_square_positive_integers _________________________ def test_square_positive_integers(): assert square(1) == 1 # Note the mistake here! We\u0026#39;ll leave this here to  # show what happens when a test fails. \u0026gt; assert square(2) == 8 E assert 4 == 8 E + where 4 = square(2) test_functions.py:10: AssertionError =========================== 1 failed in 0.16 seconds =========================== Note now, that we can see that a test has failed where we introduced the error in the test. We can now correct the test so that it\u0026rsquo;s expecting the correct answer:\ndef test_square_positive_integers(): assert square(1) == 1 assert square(2) == 4 assert square(4) == 16 assert square(100) == 10000 Now if we rerun pytest, we see something different:\n============================= test session starts ============================== platform linux -- Python 3.6.6, pytest-3.9.2, py-1.7.0, pluggy-0.8.0 -- /usr/bin/python3 cachedir: .pytest_cache rootdir: /io, inifile: collecting ... collected 1 item test_functions.py::test_square_positive_integers PASSED [100%] =========================== 1 passed in 0.21 seconds =========================== As many tests as are necessary can be written.\nExceptions Most programming languages have the concept of exceptions. An exception is just a way of handling conditions which happen while a programme is running which require special handling.\nAside: Debug Mode Many people do not know that the Python interpreter runs in \u0026lsquo;debug\u0026rsquo; mode by default. When it is disabled, by running Python with the \u0026lsquo;-O\u0026rsquo; flag, all asserts are skipped, and the flag \u0026lsquo;debug\u0026rsquo; is set to True. Utilising this can be useful when you want to check code for correctness, but know that some checks you are running can be costly in performance. It can also be used to provide more\ndef square(x): if __debug__: print(\u0026#34;We\u0026#39;re in debug mode!\u0026#34;) assert type(x) in [int, float, complex], \u0026#34;Input argument x is not of a numeric type int, complex or float\u0026#34; return x*x In debug mode, if we run the function, we get the following output:\n\u0026gt;\u0026gt;\u0026gt; square(2) We're in debug mode! 4 \u0026gt;\u0026gt;\u0026gt; square('a') We're in debug mode! Traceback (most recent call last): File \u0026quot;\u0026lt;stdin\u0026gt;\u0026quot;, line 1, in \u0026lt;module\u0026gt; File \u0026quot;\u0026lt;stdin\u0026gt;\u0026quot;, line 4, in square AssertionError: Argument is not of a numeric type  When we instead run \u0026lsquo;python3 -O\u0026rsquo;, we see:\n\u0026gt;\u0026gt;\u0026gt; square(2) 4 \u0026gt;\u0026gt;\u0026gt; square('a') Traceback (most recent call last): File \u0026quot;\u0026lt;stdin\u0026gt;\u0026quot;, line 1, in \u0026lt;module\u0026gt; File \u0026quot;\u0026lt;stdin\u0026gt;\u0026quot;, line 5, in square TypeError: can't multiply sequence by non-int of type 'str'  We can see that the print statement is completely skipped, and instead of our helpful error message which resulted from our check, we get Python\u0026rsquo;s slightly less helpful one.\nExercise: Write a first function and test The Couloumb potential is given by $$ V\\left(r\\right) = \\frac{q}{|r|} $$\n Write a function that takes two parameters, x and q, and returns this potential.\n Write a test for the function, and\n  Note: The power operator in Python is \u0026ldquo;**\u0026ldquo;, so to take the square root:\n\u0026gt;\u0026gt;\u0026gt; 4 ** 0.5 2"
},
{
	"uri": "https://scientific-programming.github.io/introduction/",
	"title": "Software Engineering in Science",
	"tags": [],
	"description": "",
	"content": " Why is it needed? The expectation is that your scientific code must be error free, within reason. However, there are many places where errors can creep in, and in general, scientists do not perform basic software engineering techniques which are designed to minimise \u0026ldquo;stupid\u0026rdquo; mistakes. Sources of errors can either be conceptual - a mistake in understanding of the theory - or in the implementation of the software used to solve problems. Here, we\u0026rsquo;re going to focus on the mistakes that come in from implementation issues, which really, are the easier ones to deal with. Let\u0026rsquo;s try and think about the issues that might happen when when things go wrong with software, both scientific and general.\nThere are a number of high profile examples which can illustrate for us the issues that might occur from coding errors.\nGeoffrey Chang Geoffrey Chang and coauthors published a series of papers in high profile journals which attempted to determine the structure of molecules through analysing X-Ray crystallography data. The research groups papers were very highly cited and influential. However, in 2006 Kasper Locher performed a similar technique to Chang to determine the structure for what should have been a similar crystal to one studied by Chang\u0026rsquo;s group. Instead, he found a 180\u0026deg; flip in the orientation of one helix, which suggested that the results were incorrect. Chang went back and looked at his software, and realised that two columns of data had been accidentally transposed, which resulted in the signs of charges in the molecular structure being flipped. In total, this led to retraction of 6 papers, and around five years of work.\nYou can read more about the impact of this here.\nReinhart and Rogoff Two economists, Reinhart and Rogoff published an influential paper \\\u0026ldquo;Growth in a time of Debt\\\u0026rdquo; on the topic of government debt to gross domestic product ratios. The results from their study showed that growth declined once the ratio reached around 60%, the growth in countries historically had begun to decline. The paper was notable for it\u0026rsquo;s use in political circles; it was cited by government figues in the UK, EU and US as the basis for reducing government spending.\nA PhD student in the US, Herndon, struggled to reproduce the results of the study, and eventually contacted the original authors of the paper requesting the non-public data that the study was based on. The authors passed this on, but Herndon and found a number of spreadsheet errors which meant that certain countries were not included in the historical data. On inclusion of these countries, the results from the paper still showed a decline in growth, but one which was substantially lower than as originally presented.\nAriane 5 Rocket Launch 1996 The launch of the first Ariane 5 rocket was a 10 year development and a $7 Billion cost for the European Space Agency. On the first test launch in June 1996 the trajectory of the rocket went of course 37 seconds in and the self destruct mechanism kicked in.\n  Investigations found that the inertial reference system had software bug, which was caused by the conversion of a 64-bit float containing the velocity into a 16-bit integer, and this caused an integer overflow. It turned out that this calculation was not even necessary on the Ariane 5, and had been inherited from software on the Ariane 4, but because this rocket reached much higher speeds, the rocket attempted to make correction for altitude deviation which hadn\u0026rsquo;t happened.\nThis was a particularly expensive mistake!\nSupercooled Water Very recent case - but went on for years. Researchers had conflicting results in simulations of supercooled water. Eventually, one group published all of their research software, which put pressure on the other group to do so. When they eventually did, it was found that they were using a very unconventional method of initialising their molecular dynamics simulations, which led to the spurious results.\nNHS Connecting for Health Stepping away from scientific software bugs, let\u0026rsquo;s look at how poor software design and oversight may hamper a different type of large software project, even when professional software developers are the ones writing it. It may surprise you to find out that in the UK, there is no national database of patient records. If you go to A\u0026amp;E on a Saturday night unconscious, in general, doctors will not be able to see your medical records until the Monday morning when your GP opens again.\nIn 2002, Tony Blair\u0026rsquo;s Labour government decided to rectify this, and in 2003 and 2004 awarded contracts to Accenture, Fujitsu, BT Health and Computer Sciences Corporation between 2002 and 2004, which the intention of building a complex set of regional systems which could integrate with one another. The initial projected timescale for this project was three years. The proposed system had an expected cost 2.3 Billion and would have been the biggest government IT project in the world.\nThe scheme was eventually cancelled in 2011 but 16 years later costs from fallout of this project are still escalating - currently at over £20 billion. Compare this, for example, to the UK budget which in 2018 is 5 billion. A government report \u0026ldquo;Government and IT - a recipe for rip offs\u0026rdquo; in 2011 blamed lack of in-house technical knowledge and a tendency to build large complex projects that cannot adapt to changing requirements.\nMore examples  A trading glitch cost Knight Capital $440 Million dollars in 30 minutes. The Therac-25 Radiation Therapy machine bug killed 4 patients and injured two others because of integer overflow in software written by a single programmer. In 1998 the Mars Climate Orbiter crashed because of imperial vs metric units in interface between software. Y2K was caused by 32-bit integer commonly used to store dates overflowing. (Upcoming again in 2038\u0026hellip;) A 1999 Study on suicides after natural disasters counted deaths in one year twice and had to be retracted. *  What are the implications of badly written software?  It\u0026rsquo;s clear that complex systems are very hard to get right. This means that starting out when writing a programme is usually not the best way of approaching it - take some time to plan. Getting things wrong for you means bad science and a damaged career. If you have to retract some work because of what amounts to carelessness, you\u0026rsquo;re going to be known in your field for getting it wrong, and it will take a lot of work to recover your reputation. Retractions are also becoming more visible! If you work on large projects it can mean huge costs in time and money if you have to redo analysis. Poorly designed software is just as bad as bugs in well designed software!  What should we draw from this?  Clear that even professional software developers can get it wrong. Scientists in particular are not generally good programmers and are mostly self taught. Scientists do not have the resources to use all of the techniques from industry to avoid problems.  Reproducibility and Repeatability  Reproducibility - Gaining results which are close in agreement using the same methodology described Key concept of the scientific method Often scientific papers cannot be reproduced solely from the paper alone. How many of you have ever struggled to reproduce a result from a computational paper? Often this comes from inherent assumptions in modelling which are not discussed in the research literature itself. Very challenging to write a paper which is complete. Large and well discussed \\\u0026ldquo;reproducibility crisis\\\u0026rdquo;  A Changing Landscape? Think now about the requirements you\u0026rsquo;re being asked to meet for research in the UK. As EPSRC funded researchers, you are already required to: * Deposit the accepted manuscript in an institutional repository so that they are openly accessible within 3 months of acceptance. * All of your research data must now be made public and be available for up to 10 years after the last 3rd party access.\nYou need to care about these things if you want to stay in academia, because if you don\u0026rsquo;t meet the requirements, your publications are not countable towards REF, which directly impacts your career path. The motivations behind these policies is that as publicly funded researchers, the general public should be able to access information you produce (with some exceptions on national security or data privacy grounds).\nMoving on from funder requirements, we need to look at what publishers are starting to demand. It is becoming increasingly necessary for you to release the source code that generates your publications. See, for example, Nature Publishing Group\u0026rsquo;s publication guidelines, which are moving in this direction. Where high quality journals start, others will follow! Looking at one particularly odd example, a 2004 paper was retracted from BMC Evolutionary Biology after the author refused to let scientists from countries admitting refugees use of the software, as this breached the journal\u0026rsquo;s guidelines on software availability.\nThe other thing to note is that other scientists - and not just funders and publishers - are becoming more demanding regarding access to software, which the recognition that complex software is often not described adequately in research papers, making the results irreproducible. Government funded organisations such as the Software Sustainability Institute are actively pushing for more research code to be made open and maintainable, and provide training. There is now a whole new career path for \u0026lsquo;Research Software Engineers\u0026rsquo; - usually former academics with strong software skills, who can provide training to academics and who are included on grant applications to work on making the research software used maintainable.\nWhat will this course teach you? Everything in the following courses is designed to make it easier for you to writing good software. In the software industry these just some starting points from which all else follows. If you are not doing any one of these things (with the exception of containerisation), you are almost certainly not writing good software. The main point is that scientific software is not some special case - it is just as complex as software in industry, where all of these are standard practice.\n"
},
{
	"uri": "https://scientific-programming.github.io/testing/complex-tests/",
	"title": "Writing Complex Tests",
	"tags": [],
	"description": "",
	"content": " Principles of Software Testing What are the main principles of software testing? Generally, people don\u0026rsquo;t start out writing software with no idea what it should do - they should have some idea of the requirements. The written software must then:\n Meet the original requirements Must respond correctly to different inputs Software must run in a reasonable amount of time Can be installed and run in the intended environment  Static vs Dynamic Testing [Static Testing]{}\n Reviews - Reviewing the code manually as a group.\n Walthrough - Parties go through a products specification to give feedback on potential defects.\n Verification of design\n  [Dynamic Testing]{}\n Executing portions of the code and checking the response.\n Validation of design\n  Why is it difficult for science?  Much of the time you don’t know what the results will be.\n Realistic problems can take time to run.\n  -\nWhy is it crucial for science?  Often need to implement new algorithms or change things.\n Changing without testing will break things.\n You might need to come back to a previous experiment to use it as the basis for a new one; if the code is broken, you will have issues!\n  Dynamic Testing: Types of Test Unit Tests  Code is written in small, independent functions\n Each function has tests that check that the result makes sense\n For e.g. a test of a function that calculates sin could check $\\sin{\\left(n\\pi\\right)} = 0 \\,\\,\\,\\,\\, \\forall n \\in \\mathbb{Z}$\n  Integration Tests  Tests check that the system as a whole works convincingly.\n For e.g. a test of a molecular dynamics code might test that the pressure is close to the expected value after some equilibrium time.\n Much, much harder to design, but essential - can be written so that they also serve as examples of how to use the software.\n  Regression Tests  Check that results don’t get less accurate over time.\n Check that performance stays the same or gets better over time.\n  Aside: Test Driven Development Methodology for testing where tests are written before writing any code.\nThis means that\u0026hellip;\n Before writing any code you need to plan out what the interface should be (i.e. what arguments get passed to functions). You must work out what the output should be before writing any code. Can form part of the ’agile’ methodology for software development. Can be difficult for developing scientific code where answers can be difficult to determine in advance.  "
},
{
	"uri": "https://scientific-programming.github.io/version-control/",
	"title": "Version Control",
	"tags": [],
	"description": "",
	"content": " What is Version Control? Simply put, it\u0026rsquo;s a way of keeping old versions of your software or documents. If you\u0026rsquo;ve ever worked in a business environment, you might be familiar with Microsoft SharePoint, and the concepts of checking in and out documents. This is an example of version control. Here, however, we\u0026rsquo;re going to teach you how to use Git, which is a more general purpose version control software. There are alternatives (Mercurial and SVN), but Git seems to have become particularly popular with the launch of the site GitHub.\nWhy is it useful? 1) Open your terminal, or Git Bash.\n2) Set your name and username with Git. This labels things you do and associates them with you!\ngit config --global user.name \u0026#34;Ryan Pepper\u0026#34; git config --global user.email \u0026#34;ryan.pepper@soton.ac.uk\u0026#34; 3) Set your favourite text editor by running the appropriate command below:\n# Atom git config --global core.editor \u0026#34;atom --wait\u0026#34; # nano git config --global core.editor \u0026#34;nano -w\u0026#34; # Sublime Text (Mac) git config --global core.editor \u0026#34;/Applications/Sublime\\ Text.app/Contents/SharedSupport/bin/subl -n -w\u0026#34; # Sublime Text (Win, 64-bit install) git config --global core.editor \u0026#34;\u0026#39;c:/program files/sublime text 3/sublime_text.exe\u0026#39; -w\u0026#34; # Notepad++ (Win, 64-bit install) git config --global core.editor \u0026#34;\u0026#39;c:/program files/Notepad++/notepad++.exe\u0026#39; -multiInst -notabbar -nosession -noPlugin\u0026#34; # Emacs git config --global core.editor \u0026#34;emacs\u0026#34; # Vim git config --global core.editor \u0026#34;vim\u0026#34; 4) We\u0026rsquo;re going to create a folder with the command \u0026ldquo;mkdir\u0026rdquo;, and change into that directory with \u0026ldquo;cd\u0026rdquo;.\ncd ~ mkdir project cd project 5) Now, we make the folder into a git repository. This means that git will start to keep track of files created in the folder.\ngit init 6) The command \u0026ldquo;ls\u0026rdquo; shows the directories contents. If we use the command \u0026ldquo;ls -a\u0026rdquo; - the \u0026ldquo;-a\u0026rdquo; flag means that we see hidden files, shows us that a new folder called \u0026ldquo;.git\u0026rdquo; has been created.\n7) We can run\ngit status to show that everything has worked correctly. You should see something like:\n# On branch master  #  # Initial commit  # nothing to commit  (create/copy files and use \u0026#34;git add\u0026#34; to track) 8) Let\u0026rsquo;s create a file; open the text editor you chose earlier, and save a file called \u0026ldquo;workshop.txt\u0026rdquo; in the directory you\u0026rsquo;re in.\nWrite something in the file:\nI\u0026#39;m learning how to use Version Control with Git! and save it.\n9) Now, let\u0026rsquo;s try running \u0026lsquo;git status\u0026rsquo; again. What you should see is that now, changes you\u0026rsquo;ve made show up.\nOn branch master No commits yet Untracked files: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed) workshop.txt nothing added to commit but untracked files present (use \u0026#34;git add\u0026#34; to track) An untracked file is just a file that we haven\u0026rsquo;t told Git to watch in any way. To track the file we created, we use the command:\ngit add workshop.txt Doing \u0026ldquo;git status\u0026rdquo; again:\nOn branch master No commits yet Changes to be committed: (use \u0026#34;git rm --cached \u0026lt;file\u0026gt;...\u0026#34; to unstage) new file: workshop.txt 10) Now, we\u0026rsquo;re going to \u0026lsquo;commit\u0026rsquo; our changes - basically, take a snapshot of them at this particular time.\nYou have two options\ni) Run the command\ngit commit This will bring up the text editor you chose earlier. Type a message about the changes you have made so that the file looks something like this:\nAdded text to workshop.txt Now save the file.\nii) Alternatively, skip opening the text editor with:\ngit commit -m \u0026ldquo;Added text to workshop.txt\u0026rdquo;\n11) Now make some more changes - add another line of text to the file workshop.txt, and commit them again.\n12) Now we\u0026rsquo;re going to look at the record we\u0026rsquo;ve made so far. Try runningt the command:\nWhat you should see is something like the following: ```bash commit 3ef8ea1e42fc071b8f8121ba80419b9df6f5d983 (HEAD -\u0026gt; master) Author: Ryan Pepper \u0026lt;ryan.pepper@soton.ac.uk\u0026gt; Date: Wed Oct 24 15:04:12 2018 +0100 Added more text to workshop.txt commit dc6b701bcdbff38fa8a9800f8173f88d514090ac Author: Ryan Pepper \u0026lt;ryan.pepper@soton.ac.uk\u0026gt; Date: Wed Oct 24 14:17:36 2018 +0100 Add text to workshop.txt ``` Breaking this down - there are two sections, for the two commits you\u0026#39;ve made so far, ordered from newest to oldest. The big long strings are a label for a particular set of changes. Author and date are self-explanatory, and the text below that is the message 13) Now, let\u0026#39;s say that you need to go back in time and look at how the file looked some time ago. We could just delete the text, but in more complicated cases, that\u0026#39;s not sufficient. There is an easy way to go back. Copy about 10 or so of the first letters and numbers of the commit that you want to see. Then run the command: ```bash git checkout dc6b701bcdbff ``` You will see some output: ``` Note: checking out \u0026#39;dc6b701bcdbff38f\u0026#39;. You are in \u0026#39;detached HEAD\u0026#39; state. You can look around, make experimental changes and commit them, and you can discard any commits you make in this state without impacting any branches by performing another checkout. 14) If you want to create a new branch to retain commits you create, you may do so (now or later) by using -b with the checkout command again. Example: git checkout -b \u0026lt;new-branch-name\u0026gt; HEAD is now at dc6b701 Add text to workshop.txt You\u0026rsquo;re now in a working environment with the old set of changes - if you open the file again, you can see the latest committed changes have disappeared. Don\u0026rsquo;t worry! They\u0026rsquo;re safe. You\u0026rsquo;re in something called a \u0026lsquo;detached HEAD\u0026rsquo; state. This is often a source of a lot of confusion for people new to Git, because if you make commits in this state, they will get lost.\nNow is a good time to introduce the concept of a branch. Branches are basically a parallel stream of commits that you can work on seperately, and switch to at any time. The \u0026ldquo;main\u0026rdquo; branch - the master copy of the history is known as the \u0026ldquo;master\u0026rdquo; branch. You can have as many branches as you like in a repository. The main use case is for fixing bugs or From the detached head state, or any other place, you can create a branch by running:\ngit checkout -b mynewbranch Git checkout is for switching between branches; the \u0026ldquo;-b\u0026rdquo; flag creates new ones.\n15) From here, we can make changes. Add some more text in the file workshop.txt and commit the changes.\nYou can switch back to the original history by running the command:\ngit checkout master 16) Now you can try and merge the branch into the \u0026lsquo;master\u0026rsquo; branch. To do this, run the command:\ngit merge mybranch However, you may see an error message:\nAuto-merging workshop.txt CONFLICT (content): Merge conflict in workshop.txt Automatic merge failed; fix conflicts and then commit the result.  What this means is that Git cannot automatically reconcile the differences between the version of the file in your new branch, and the version of the file in your master branch. This is called a \u0026lsquo;merge conflict\u0026rsquo; That means you manually need to edit the file. Edit the file and you will see three odd lines with special markers:\nHello, we've got a file in here! \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; HEAD Added a line of text on the branch! ======= Added another line to the file. \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; mybranch  The \u0026ldquo;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; HEAD\u0026rdquo; means that what follows is text on the head of the current branch - i.e. mynewbranch.\nThe \u0026ldquo;=======\u0026rdquo; acts as a seperator\nThe \u0026ldquo;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; master\u0026rdquo; signals the end of the conflicting changes on the master branch.\nTo reconcile, simply delete these three lines, and save the file. Do a \u0026lsquo;git add\u0026rsquo; and then \u0026lsquo;git commit\u0026rsquo;\nStoring your repository somewhere safe You have a history of your changes locally, but that\u0026rsquo;s not much good if your hard drive fails. We\u0026rsquo;ll now show you how keep a history remotely.\nGit is known as a \u0026lsquo;distributed version control\u0026rsquo; system. Generally, you host a repository somewhere online. There are lots of different providers for this.\n GitHub - free! Lots of integrations with other services. Limited number or private repositories, but you can send off proof of academic status to get an unlimited number.\n GitLab - also free. Unlimited number of private repositories. Also allows local hosting - for e.g. in the University of Southampton, there is a private GitLab instance hosted internally, which can be used for sensitive projects.\n BitBucket - Has a lot of commercial products that are used in industry - good issue trackers.\n  For this exercise, we\u0026rsquo;ll use GitHub, but in practice there is not much between them.\n1) Create an account on github.com\n2) Once done, click the \u0026ldquo;+\u0026rdquo; arrow in the top right hand corner, and click \u0026ldquo;New repository\u0026rdquo;\n3) Type in a name and description for your repository:\nYou\u0026rsquo;ll now get a list of commands to type; the ones you want are:\ngit remote add origin https://github.com/rpep/mytestrepo.git git push -u origin master You\u0026rsquo;ll get asked for your username and password for GitHub - enter these.\nNow refresh the page, and you\u0026rsquo;ll see the file you had has appeared online!\n4) Now - in pairs - one of you go to the Git repository of your neighbour. This will be\nhttps://github.com/their-username/their-repository-name\nClick \u0026lsquo;Fork\u0026rsquo;. This will make a copy of their repository on your GitHub.\n5) Now, copy their repository to your computer with the command:\ngit clone https://github.com/yourusername/their-repository-name.git 6) Move into the folder:\ncd their-repository-name And make your own change to the file.\n7) Commit it as before:\ngit commit -m \u0026#34;Making a change to my partner\u0026#39;s repository\u0026#34; 8) Now push the change online:\ngit push 9) Go back to GitHub.\nClick \u0026ldquo;New Pull Request, and then \u0026ldquo;Create New Pull Request\u0026rdquo; on the next page.\nAdd in some information about the changes you made, and then \u0026ldquo;Create pull request\u0026rdquo;\n10) Now, your partner needs to go back to their version of the repository, and look at the tab labelled \u0026ldquo;Pull Requests\u0026rdquo;\nScroll to the bottom, and then press \u0026ldquo;Merge pull request\u0026rdquo;\n"
},
{
	"uri": "https://scientific-programming.github.io/containers/tutorial/",
	"title": "Getting Started with Docker",
	"tags": [],
	"description": "",
	"content": " First Steps 1) Make an account on the website https://hub.docker.com\nMake the username something sensible as we\u0026rsquo;ll have to use it soon!\n1) If you haven\u0026rsquo;t already, try \u0026ldquo;docker run ubuntu:18.04\u0026rdquo;. This downloads an image containing Ubuntu 18.04.\n2) Now, we\u0026rsquo;ll create a file called \u0026ldquo;Dockerfile\u0026rdquo; in a single folder. The Dockerfile is a configuration script for building an image.\n Create a directory by doing:  mkdir docker-tutorial  Change directory into the folder:  cd docker-tutorial 3) Create a file called Dockerfile in this directory, and put as the first line:\nfromubuntu:18.04\u0026#39; 4) Now, we can start installing things inside the image. We do this by adding lines to the Dockerfile; a command to run is prefaced by \u0026ldquo;RUN\u0026rdquo;. If you\u0026rsquo;re not familiar with Linux, and are primarily a Windows or Mac user, it may seem a little odd to install programmes using typed out commands, but it can be very powerful. For Ubuntu, there are basically two commands you need to know.\nFirst, we\u0026rsquo;ll update the list of Ubuntu packages which can be installed; note that this is almost always necessary. To do this, add:\nRUN apt-get update to the file.\n6) Once this is completed, you can then choose to install programmes. We\u0026rsquo;re going to use Python for this example, but you can pick any programmes you like for your own Docker containers. Here, we just add the line:\nRUN apt-get install -y python3 which tells Ubuntu to install Python 3 in the container. The \u0026ldquo;-y\u0026rdquo; flag here just tells apt-get, the programme used in Ubuntu for installing programmes, not to prompt for confirmation.\nNow, you have a script which tells Docker to build a container which: * Is based on Ubuntu 18.04. You could change this to another Linux distribution if you wanted, such as CentOS. * Contains Python 3.\nThis is the general principle of containers - you build them up in steps until they have everything you need to run real applications.\nNow, we can tell Docker to run a command when the container is launched. We do this using a slightly different syntax:\nCMD /bin/bash  This just tells Docker to launch the Bash shell. From this, we can launch all of the programmes installed into the container. Alternatively, we could just as easily write:\nCMD / 7) Now let's actually build the container image from the script file. We do this using the following command - replace \u0026quot;YOURUSERNAME\u0026quot; with your username for the account we created with Dockerhub earlier. ```Bash docker build . -t YOURUSERNAME/myimage  Breaking this command down:\n Docker is the application.\n We\u0026rsquo;re running Docker\u0026rsquo;s build command\n \u0026rdquo;.\u0026rdquo; refers to the file location - it\u0026rsquo;s saying \u0026ldquo;build the Dockerfile in this folder\u0026rdquo;\n -t YOURUSERNAME/myimage - if you\u0026rsquo;re not familiar with Linux, adding a dash is a common way of signalling how to pass information to a command. Here, \u0026ldquo;-t\u0026rdquo; just means build the image with the tag YOURUSERNAME/myimage\n  More concepts Every time you add another command to the script, you create a new layer. A layer is the essentially just a list of differences between the previous command and the present one. Your container image is built up of multiple layers. If you want to add a new command, you don\u0026rsquo;t have to rebuild completely from scratch - Docker is clever enough to start from the last common layer. These layers do take up storage space, however.\nThat means though, if you change the programmes installed with apt-get on the second line of the script, all subsequent steps must be repeated, because Docker can\u0026rsquo;t work out if subsequent steps are independent or not of each other.\n7) Now we\u0026rsquo;ve installed python3 in the image, how do we use it?\nWe can do this in two ways - similar but quite different!\n1) Start a container from the image interactively, and launch the programme:\nTo run interactively, we must add the \u0026ldquo;-i\u0026rdquo; flag. If we don\u0026rsquo;t do this, the programme will launch, but will freeze!\ndocker run -i -t YOURUSERNAME/myimage Then, just run\npython3  to launch the Python interpreter.\n2) * Create a container from the image, and give it the name \u0026lsquo;mytest\u0026rsquo;\ndocker create --name mytest YOURUSERNAME/myimage  Then, start the container:  docker start --name mytest *\nSaving the Container 1) We can save the docker container to a file with\ndocker save YOURUSERNAME/mycontainer \u0026gt; myimage.tar You can compress the image if you want with the command\ngzip -f myimage.tar You can load it again with\ndocker load myimage.tar.gz 2) However, it\u0026rsquo;s not normally necessary to save containers like this - much easier just to use Docker Hub. Free uploads of containers if public, one private container per account.\nMake a repository called \u0026lsquo;mycontainer\u0026rsquo; on your Dockerhub account\n3) Now, on your computer, run the command:\ndocker login  You will be prompted for your username and password for Dockerhub. Enter them.\n11) Now, we can publish the container online using:\ndocker push YOURUSERNAME/mycontainer 12) Your container should now be available online. That means, someone else can download it using the \u0026lsquo;docker pull\u0026rsquo; command, and run the same programmes as you in the same way.\n13) Just to prove it to you, let\u0026rsquo;s now delete the containers.\nThere are lots of commands for deleting containers and images - this is quite confusing!\nIf you want to remove everything, you can run:\ndocker system prune Deletes everything that are not associated with a running container - \u0026ldquo;dangling\u0026rdquo;. Add the \u0026ldquo;-a\u0026rdquo; flag to remove additionally any stopped containers and all unused images.\nIf you just want to remove a specific image, you can run\ndocker images This gives a list of all images you\u0026rsquo;ve created, including intermediate layers. Copy the image id (the long string of numbers) of the image you want to remove:\ndocker rmi IMAGEID You may need to add the flag \u0026lsquo;-f\u0026rsquo; if you get an error here:\ndocker rmi IMAGEID -f  Note: if other images depend on the image you are deleting, they will also be deleted!\nRemove all images:\ndocker images -a docker rmi $(docker images -a -q) 14) Now pull the image we uploaded:\ndocker pull YOURUSERNAME/dependencies  Further steps TBD: Check Windows mount path syntax\nOften, we want to install programmes in the container in order to manage dependencies, but we need to have them act on files stored on the computer itself. This can easily be achieved by mounting folders into the container, so that they are visible inside it.\nTBD: Mounting Ports: Explain what ports are? Networking end points - send messags between? Is this sufficient? TCP vs UDB - Docker uses TCP by default. Not sure this is relevant to mention.\n"
},
{
	"uri": "https://scientific-programming.github.io/containers/",
	"title": "Containers",
	"tags": [],
	"description": "",
	"content": " What are containers?  Mechanism for setting up environment Allows control of dependencies Describes setup process through scripting in standardised manner Can be easily distributed to other developers (binary vs script) Not a virtual machine (in most cases\u0026hellip;)  What are containers not?  Not the best way to distribute software, especially in scientific use cases. An excuse not to write down strict dependency requirements for your software (e.g. versions of libraries). A way of avoiding updating scientific software because it now runs everywhere.  Terminology  Host - Computer running VM/container. Image - Binary file Hypervisor - software running VM. Kernel - Core OS components  Comparisons with Virtual Machines How are containers like VMs?  Isolated environment - Processes run isolated from other processes - they can’t access hardware resources they aren’t allocated. They are independent - Generally you can be given a container image or a virtual machine image and use that to run a piece of software without doing anything else.  How are containers not like VMs?  They use Kernel features of the host Linux supports process and resource partitioning and isolation (cgroups, OverlayFS, kernel namespacing), which allows containers to use a subset of resources.\n VMs require a Hypervisor The hypervisor is a software based emulation layer for computer hardware and so it is generally 20% slower running software in a VM than natively, even with Intel Vf-X, Sun GridEngine. Free hypervisors slow; commercial are expensive!\n Generally containers are command-line only With VMs it is very easy to get a full desktop environment. With containers this use case is generally not well supported.\n They take up much less space Virtual Machines have to bundle the whole operating system, including components which would be the same on the host system. Containers, by virtue of using the host system\u0026rsquo;s kernel (at least on Linux), can therefore take up much less room.\n  Potential Use Cases for Containers  A new PhD student joins your lab. He isn\u0026rsquo;t an experienced programmer, and setting him up with all of the dependencies will take some time. Using a container means he can get all of the dependencies and a copy of the software working on his computer in minutes.\n An old piece of software runs fine on Ubuntu, but a colleague hasn\u0026rsquo;t been able to install a necessary package because it\u0026rsquo;s not available on Windows which is what he uses.\n You\u0026rsquo;ve just been given an Microsoft Azure Academic Grant, and you now want to run thousands of copies of your research software in the cloud, and you want to avoid a complicated install process.\n You have a data analysis script that chugs away on your desktop for every set of simulation data you produce. You want to run it on your Universities HPC cluster, but you\u0026rsquo;re not sure how to compile all of the dependencies from source, which is what you\u0026rsquo;d need to do otherwise.\n  "
},
{
	"uri": "https://scientific-programming.github.io/testing/",
	"title": "Testing Scientific Code",
	"tags": [],
	"description": "",
	"content": " What is a software test? Software tests are written in order to check that the implementation of software is correct, and to guard against dangerous behaviour. They\u0026rsquo;re used to make software run in a safer manner; if we know what the inputs and outputs of sofware should be, and we know that for those inputs the answer is correct, we can have some confidence that the software is correct.\nWhy is this important? Consider how science works in experimental science. We try and apply the scientific method:\nScientific Method A set of rough principles:\n Ask a question. Form a hypothesis. Make a prediction based on the hypothesis. Design an experiment to test the hypothesis. Build the equipment Calibrate equipment by testing it Run the experiment Detail carefully the procedures and record information. Draw conclusions from results.    Consider whether, when writing software to do science, you check that your \u0026lsquo;equipment\u0026rsquo; is calibrated? In many cases, the answer will be no.\nWhy might this be the case? Often ad-hoc changes are made to code which mean things stop working. Have you ever come back to a script that you wrote and found it no longer works because you changed a file somewhere else? These issues become especially common when multiple people, who might not have oversight over what you are using it for, are working on software.\nIn this tutorial, we\u0026rsquo;ll step through some examples in the Python language which aim to show how you can write tests, and incorporate them into your own software in practice.\nStarting off simply: Squaring a number Consider as an example, a function which takes a number and computes the square of that number.\ndef square(x): return x * x Various appropriate tests of this could check:\n Is the correct answer given for positive integers? Is the correct answer given for negative integers? Is the correct answer given for zero? Is the correct answer given for positive and negative decimals? What is the behaviour for complex numbers? How does the function behave when an input argument is not of the type specified is passed in (such as a string)?  It\u0026rsquo;s clear that all of these would be sensible, but considering it carefully, it shows immediately the difficulty of actually applying testing in practice. There are an infinite amount of numerical input arguments - we cannot reasonably test them all.\nPrinciples of Software Testing  Software must meet the requirements\n Software must respond correctly to different inputs\n Software must run in a reasonable amount of time\n Can be installed and run in the intended environment\n  Static vs Dynamic Testing [Static Testing]{}\n Reviews - Reviewing the code manually as a group.\n Walthrough - Parties go through a products specification to give feedback on potential defects.\n Verification of design\n  [Dynamic Testing]{}\n Executing portions of the code and checking the response.\n Validation of design\n  Why is it difficult for science?  Much of the time you don’t know what the results will be.\n Realistic problems can take time to run.\n  -\nWhy is it crucial for science?  Often need to implement new algorithms or change things.\n Changing without testing will break things.\n You might need to come back to a previous experiment to use it as the basis for a new one; if the code is broken, you will have issues!\n  Dynamic Testing: Types of Test Unit Tests  Code is written in small, independent functions\n Each function has tests that check that the result makes sense\n For e.g. a test of a function that calculates sin could check $\\sin{\\left(n\\pi\\right)} = 0 \\,\\,\\,\\,\\, \\forall n \\in \\mathbb{Z}$\n  Integration Tests  Tests check that the system as a whole works convincingly.\n For e.g. a test of a molecular dynamics code might test that the pressure is close to the expected value after some equilibrium time.\n Much, much harder to design, but essential - can be written so that they also serve as examples of how to use the software.\n  Regression Tests  Check that results don’t get less accurate over time.\n Check that performance stays the same or gets better over time.\n  Aside: Test Driven Development Methodology for testing where tests are written before writing any code.\nThis means that\u0026hellip;\n Before writing any code you need to plan out what the interface should be (i.e. what arguments get passed to functions). You must work out what the output should be before writing any code. Can form part of the ’agile’ methodology for software development. Can be difficult for developing scientific code where answers can be difficult to determine in advance.  "
},
{
	"uri": "https://scientific-programming.github.io/documentation/",
	"title": "Documentation",
	"tags": [],
	"description": "",
	"content": " What makes good documentation on a software project? Nothing can frustrate a user more than coming across a project which has inadequate documentation; without a knowledge of the underpinnings of a software library, the user must either field questions to the authors if they, indeed, are able to take them, or begin to study the source code in detail. This, however, causes many problems. Perhaps the user has no expertise in the area they wish to look at, and the source code is beyond their understanding. It may be that they get so frustrated that they begin to reimplement parts of a library themselves, to avoid having to work with code that they have not written. A piece of software may provide the most elegant solutions in the world for a particular problem, but if users find that they are unable to work with it through a lack of understanding about what the constituent parts do, it is unlikely to see much uptake.\nWhat makes good documentation? There are broadly two types of documentation for software libraries:\n API Documentation - This describes all of the functions that are usable, specifying the input arguments, the behaviour of the function and the return values.\n Examples - Providing examples in context, which show how to use the particular functions, showing particular input values explicitly and what the results are.\n  In general, the best software documentation contains both detailed documentation of the API and examples along with it. Why is this the case?\nIf you want to quickly use a library, and know roughly what you\u0026rsquo;re looking for, examples are normally the quickest way to get started. On the other hand, if you need to use more sophisticated features of a library, you\u0026rsquo;re likely to need the API documentation, because it gives more details of the \u0026lsquo;advanced\u0026rsquo; features. A good rule of thumb when writing documentation is that examples should try and show \u0026lsquo;enough\u0026rsquo; - if there are any pitfalls that might be non-obvious, it\u0026rsquo;s better to point these out and save users any pain.\nPerhaps the best way to learn what software documentation should look like is the use and study of projects which are well documented. We\u0026rsquo;ll look here at an example from the the Python library SciPy.\nNewton Raphson documentation Consider the Newton-Raphson algorithm we used as an example in the testing section of these tutorials. The iterative procedure for finding the root of a function is given by:\n$$ x_{n+1} = x_{n} - \\frac{f(x_n)}{f\u0026rsquo;(x_n)} $$\nBecause this is such a ubiquitous method, it\u0026rsquo;s a good one for us to consider when looking at documentation.\nLet\u0026rsquo;s take a look at the SciPy documentation for this function. The descriptions of the parameters in the whole of the SciPy library (and also the NumPy library) are written to a set of standards. These standards are defined in the documentation here, and they are worth a read to anyone writing software as they are something of a gold standard. Indeed, many other Python projects implement documentation in the same format as these libraries. Here we\u0026rsquo;ll just discuss briefly the main features:\nWe can see first that it starts first with the function signature (i.e. the input arguments), and both a brief and long form description:\nscipy.optimize.newton(func, x0, fprime=None, args=(), tol=1.48e-08, maxiter=50, fprime2=None) Find a zero using the Newton-Raphson or secant method. Find a zero of the function func given a nearby starting point x0. The Newton-Raphson method is used if the derivative fprime of func is provided, otherwise the secant method is used. If the second order derivative fprime2 of func is provided, then Halley’s method is used.  The function signature tells us the input arguments, but without some thought, it would still be difficult to immediately use the function. The description tells us the key information about the particular function, and a bit of brief clarifying information about the function. The key parts, however, are really what follow:\n Parameters: func : function The function whose zero is wanted. It must be a function of a single variable of the form f(x,a,b,c…), where a,b,c… are extra arguments that can be passed in the args parameter. x0 : float An initial estimate of the zero that should be somewhere near the actual zero. fprime : function, optional The derivative of the function when available and convenient. If it is None (default), then the secant method is used. args : tuple, optional Extra arguments to be used in the function call. tol : float, optional The allowable error of the zero value. maxiter : int, optional Maximum number of iterations. fprime2 : function, optional The second order derivative of the function when available and convenient. If it is None (default), then the normal Newton-Raphson or the secant method is used. If it is not None, then Halley’s method is used. Returns: zero : float Estimated location where function is zero.  Each input and output parameter has its type specified - especially necessary in Python given that it is a dynamically-typed language. Some parameters, which are optional, are stated as such. We note that the default values for the optional arguments were given above in the function signature. Then, following each parameter is a description of the input parameters.\nFollowing these, examples are given on how to use the function:\n\u0026gt;\u0026gt;\u0026gt; def f(x): ... return (x**3 - 1) # only one real root at x = 1 \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; from scipy import optimize # fprime not provided, use secant method \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; root = optimize.newton(f, 1.5) \u0026gt;\u0026gt;\u0026gt; root 1.0000000000000016 \u0026gt;\u0026gt;\u0026gt; root = optimize.newton(f, 1.5, fprime2=lambda x: 6 * x) \u0026gt;\u0026gt;\u0026gt; root 1.0000000000000016 # Only fprime provided, use Newton Raphson method \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; root = optimize.newton(f, 1.5, fprime=lambda x: 3 * x**2) \u0026gt;\u0026gt;\u0026gt; root 1.0 # Both fprime2 and fprime provided, use Halley’s method \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; root = optimize.newton(f, 1.5, fprime=lambda x: 3 * x**2, ... fprime2=lambda x: 6 * x) \u0026gt;\u0026gt;\u0026gt; root 1.0 Note that several different perturbations of the input arguments are given. For most people, it would be enough to briefly look at the examples here, and they would immediately be able to get started with using the code.\nWhat\u0026rsquo;s particularly invaluable here is that both the function API documentation and the examples are given in the same place. This makes it quick to get started with using the code. In contrast, many software libraries provide examples and the API, but separate from each other.\n"
},
{
	"uri": "https://scientific-programming.github.io/cheatsheet/",
	"title": "Cheatsheet",
	"tags": [],
	"description": "",
	"content": "The following is a list of standard commands in cmd on Windows or Bash on *nix systems. It\u0026rsquo;s by no means a comprehensive list - these are just to help you\nSometimes the commands I\u0026rsquo;ll show (which are used for navigating around on Linux or Unix based systems like Macs) don\u0026rsquo;t work in Windows. So here, I\u0026rsquo;ve put a list of things you might want to do, and the commands in both Windows and Linux.\n   Concept Windows cmd command Linux     Run a file filenme ./filename   Change directory into folder X cd X cd X   List files dir ls   Show the current directory cd pwd   Copy filenamed A to B copy A B cp A B   Delete file A del A rm A   Delete folder A rmdir A rm -r A   Move file A to B move A B mv A B   Create a folder called A mkdir A mkdir A    "
},
{
	"uri": "https://scientific-programming.github.io/documentation/generating-docs/",
	"title": "Generating Docs",
	"tags": [],
	"description": "",
	"content": " How can we generate documentation from code? There are a number of different tools for automatically generating documentation for different languages. For Python, a common tool is Sphinx. For projects which combine several languages, sometimes the tool Doxygen is preferred.\nHere, we\u0026rsquo;ll focus on Sphinx, but generally all tools work by similar principles; the source code of a library is parsed, and the author of code annotates it in order to provide the documentation.\nIn Python, we can document a function with a documentation string, or \u0026lsquo;docstring.\u0026rsquo; These are provided as a multi-line string just under the function signature in the source code.\nConsider our simple \u0026lsquo;squared\u0026rsquo; and \u0026lsquo;power\u0026rsquo; functions from the testing tutorial:\ndef squared(x): return x * x def power(x, n): return x ** n An annotated version of \u0026lsquo;squared\u0026rsquo;, using the NumPy documentation standard, could be:\ndef squared(x): \u0026#34;\u0026#34;\u0026#34; Returns the square of the input x Parameters: ----------- x, float: Base number Returns: -------- float: Base number raised to power 2 See Also: ------ pow : raise an argument to an arbitrary power Examples -------- \u0026gt;\u0026gt;\u0026gt; squared(2) 4 \u0026gt;\u0026gt;\u0026gt; squared(8) 64 \u0026gt;\u0026gt; squared(-1) 1 \u0026#34;\u0026#34;\u0026#34; return x*x This might seem verbose, but, everything that\u0026rsquo;s needed is there.\nAccessing the documentation from Python Accessing Documentation from Python If you\u0026rsquo;re in a Python interpreter, you can access the documentation by calling the help function with the name of the function or class you\u0026rsquo;re interested in:\n\u0026gt;\u0026gt;\u0026gt; help(function_name)  "
},
{
	"uri": "https://scientific-programming.github.io/documentation/generating-sphinx/",
	"title": "Generating documentation with Sphinx",
	"tags": [],
	"description": "",
	"content": " Quick Notes  Pip install sphinx rather than through apt-get because otherwise TZ settings do not work well  fromubuntu:18.04RUN apt-get update \u0026amp;\u0026amp; apt-get install python3 python3-pipRUN pip3 installWORKDIR/app Then\ndocker build . -t documentation docker run -v `pwd`:/app -it documentation sphinx-quickstart  Most defaults are OK but:\n We want to set default document to markdown rather than RST We want to enable MathJax  Now Edit conf.py:\n  Uncomment these lines of code in conf.py\n# If extensions (or modules to document with autodoc) are in another directory, # add these directories to sys.path here. If the directory is relative to the # documentation root, use os.path.abspath to make it absolute, like shown here. # # import os # import sys # sys.path.insert(0, os.path.abspath(\u0026#39;.\u0026#39;))  to extensions add sphinx.extensions.doctest and sphinx.extensions.napoleon napoleon allows NumPy style documentation after extension declarations add following:  napoleon_google_docstring = False doctest_global_setup = \u0026#34;\u0026#34;\u0026#34; from quicktest import * \u0026#34;\u0026#34;\u0026#34; Then, from root dir:\nsphinx-apidoc -s md -o source ../quicktest make html  Note: -s flag changes suffix from rst autodoc to md autodoc. source is output directory quicktest is source code directory\n Create a file called tutorial.rst  Tutorial ======== This is a tutorial.Subheading ---------- Here is some text under a subheading In index, change the toctree (table of contents tree) to:\n.. toctree:: :maxdepth: 2 :caption: Contents: tutorial Now, \u0026lsquo;make html\u0026rsquo;\nYou can see that the tutorial page has appeared in the documentation.\nPutting online  Log in to RTD with GitHub acct\n Import Repository\n Select correct repo\n Click build\n Builds automatically\n  "
},
{
	"uri": "https://scientific-programming.github.io/documentation/writing-docs/",
	"title": "Sphinx: Python documentation",
	"tags": [],
	"description": "",
	"content": " Installing Sphinx We\u0026rsquo;ll start with a Docker container (again!). Build the following:\nfromubuntu:18.04ENVTZ \u0026#34;Europe/London\u0026#34;RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime \u0026amp;\u0026amp; echo $TZ \u0026gt; /etc/timezoneRUN apt-get update \u0026amp;\u0026amp; apt-get install -y python3 python3-pip python3-sphinxWORKDIR/app with the command:\ndocker build . -t sphinx Note that we\u0026rsquo;ve had to add some timezone information into the container here; don\u0026rsquo;t worry too much about this.\nNow, go to the repository in which you have your Python files.\n"
},
{
	"uri": "https://scientific-programming.github.io/testing/continuous-integration/",
	"title": "Continuous Integration",
	"tags": [],
	"description": "",
	"content": " Continuous Integration What is Continuous Integration?\n Runs the tests repeatedly, every time you make a change. You use a remote service, to avoid having to run all tests locally - useful if they take some time to run. Generally, CI services send you angry emails when tests fail! It requires you to be using version control, and all tests are run when you push your changes to the remote repository. If you are developing a new feature, tests also get run when you\u0026rsquo;re developing features in a branch/fork.  There are a number of ways to do CI. If you don\u0026rsquo;t have a server, and you\u0026rsquo;re happy for your project to be hosted remotely on GitHub or on another site, you can use remote services such as TravisCI, CircleCI and GitLab. If you have your own server, and you need everything to be private (sometimes this is the case if you\u0026rsquo;re working on academic work with industry partners), then there are services you can host locally such as Jenkins and Buildbot.\nTravisCI We\u0026rsquo;ll here pick this, as it’s easy to set up from what we’ve already done:\nFirst, log in to Travis CI with your GitHub account.\nNow, to build our repository, we\u0026rsquo;ll need to put a very simple Travis configuration file into the root of the Git repository. Create a file called \u0026lsquo;.travis.yml\u0026rsquo;. This is written in a markup language called YAML, but the syntax for this is very simple.\nTravis comes preinstalled with many programming languages, but uses an older version of Ubuntu. Because we have used Docker throughout to run our software, however, we can just use this as the basis on Travis to run our software. We need to specify only a few options, and everything is set up for us:\nsudo: required services: - docker  These options just tell travis that root permissions are needed (a requirement for Docker itself), and we need Docker to be installed.\nWhen Travis builds first start, they clone the latest commit from the Git repository, and then change directory into that folder. So from then on, you can write out commands referring to files in that folder.\nSo now, we want to get the right environment to run our tests. Let\u0026rsquo;s build the Docker container from the Dockerfile in our repository. Add the following lines.\nbefore_install: - docker build . -t build  The before_install section here tells Travis to run the bash command on the subsequent line. This is normally where you run any setup which is needed to run the tests.\nNow, we\u0026rsquo;ve done everything we need to do before running the tests, so let\u0026rsquo;s put in the command to run them. We do this in a \u0026lsquo;script\u0026rsquo; block:\nscript: - docker run -v`pwd`:/io build pytest -v .  The total file should now look like:\nsudo: required services: - docker before_install: - docker build . -t build script: - docker run -v`pwd`:/io build pytest -v .  Stage this file in your Git repository and commit it. Push it to GitHub, then navigate to the Travis website again. You should now see that your repository has appeared, and that a build is in progress. If everything is correct, your Python tests should run remotely!\nClearly, we could have much more complex build processes than this, and you run Python inside the build environment rather than in a Docker container. However, it\u0026rsquo;s in general a good idea to delegate these into a container, as it avoids you having to duplicate the install script in multiple places, and keeps the development environment where you work the same as the test environment.\nShowing this on GitHub. One common thing to do is to add a readme file to a GitHub repository. Generally these just give some information for people who come across the project, such as install instructions. These files are typically written in Markdown - a simple syntax which is widely used online in forums and in many other places. A simple README.md, written in Markdown, for this project could be:\n# Testing and CI This repository follows the material on https://scientific-programming.github.ioto create a repository with simple Python tests and Continuous Integration set up. We can add a badge to this to show the status of the build (i.e. passing or failing). Go to the Travis page for your repository.\nWorkflow A normal workflow for continuous integration is often something like:\n Create a branch or a fork of a repository to work on a new feature. Write some tests, and run ones relevant to the changes you\u0026rsquo;re making on your local machine. Commit changes, and push to the remote repository. If any tests fail, you\u0026rsquo;ll get a notification of this, and you can fix them.  However, it can also be useful to set up tests to run at periodic intervals - i.e. nightly. This means that if a dependency unexpectedly changes in a repository that you\u0026rsquo;re not actively contributing to,\n"
},
{
	"uri": "https://scientific-programming.github.io/testing/writing-tests/",
	"title": "Writing Tests",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://scientific-programming.github.io/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://scientific-programming.github.io/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]